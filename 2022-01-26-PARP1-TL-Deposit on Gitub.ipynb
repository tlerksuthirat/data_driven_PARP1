{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88acee6",
   "metadata": {},
   "source": [
    "### Derived from 2022-01-26-PARP1-TL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62069880",
   "metadata": {},
   "source": [
    "### 01_Retrieve PARP1 from ChEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chembl_webresource_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda51e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from chembl_webresource_client.new_client import new_client\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = new_client.target\n",
    "target_query = target.search('PARP1')\n",
    "targets = pd.DataFrame.from_dict(target_query)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_target = targets.target_chembl_id[0]\n",
    "selected_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68718556",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = new_client.activity\n",
    "raw = ac.filter(target_chembl_id=selected_target)\n",
    "df0 = pd.DataFrame.from_dict(raw)\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.to_csv('PARP1_00_bioactivity_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66abe9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_IC50 = ac.filter(target_chembl_id=selected_target).filter(standard_type=\"IC50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IC50 = pd.DataFrame.from_dict(res_IC50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IC50.to_csv('PARP1_01_bioactivity_IC50_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58cfc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove missing data\n",
    "df2_IC50 = df_IC50[df_IC50.standard_value.notna()]\n",
    "df2_IC50 = df2_IC50[df_IC50.canonical_smiles.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicate data in canonical_smiles column\n",
    "df2_nr_IC50 = df2_IC50.drop_duplicates(['canonical_smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 3 column for further analysis\n",
    "selection = ['molecule_chembl_id','canonical_smiles','standard_value']\n",
    "df3_IC50 = df2_nr_IC50[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07aa63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_IC50.to_csv('PARP1_02_bioactivity_IC50_data_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342113ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_IC50 = pd.read_csv('PARP1_02_bioactivity_IC50_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioactivity_threshold = []\n",
    "for i in df4_IC50.standard_value:\n",
    "  if float(i) >= 10000:\n",
    "    bioactivity_threshold.append(\"inactive\")\n",
    "  elif float(i) <= 1000:\n",
    "    bioactivity_threshold.append(\"active\")\n",
    "  else:\n",
    "    bioactivity_threshold.append(\"intermediate\")\n",
    "    \n",
    "bioactivity_class = pd.Series(bioactivity_threshold, name='class')\n",
    "df5_IC50 = pd.concat([df4_IC50, bioactivity_class], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_IC50.to_csv('PARP1_03_bioactivity_IC50_data_curated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029d138",
   "metadata": {},
   "source": [
    "### 02_Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823908cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run with python 3.7\n",
    "! conda install -c rdkit rdkit -y\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PARP1_03_bioactivity_IC50_data_curated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8047cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0158bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ac = df['class'].value_counts()\n",
    "class_ac.columns = ['class','count']\n",
    "class_table = pd.DataFrame(class_ac)\n",
    "class_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_table.to_csv('PARP1_bioactivity_profile_IC50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c614c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_smiles = df.drop(columns='canonical_smiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b17af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = []\n",
    "\n",
    "for i in df.canonical_smiles.tolist():\n",
    "  cpd = str(i).split('.')\n",
    "  cpd_longest = max(cpd, key = len)\n",
    "  smiles.append(cpd_longest)\n",
    "\n",
    "smiles = pd.Series(smiles, name = 'canonical_smiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_smiles = pd.concat([df_no_smiles,smiles], axis=1)\n",
    "df_clean_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d32b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Lipinski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad43e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by: https://codeocean.com/explore/capsules?query=tag:data-curation\n",
    "\n",
    "def lipinski(smiles, verbose=False):\n",
    "\n",
    "    moldata= []\n",
    "    for elem in smiles:\n",
    "        mol=Chem.MolFromSmiles(elem) \n",
    "        moldata.append(mol)\n",
    "       \n",
    "    baseData= np.arange(1,1)\n",
    "    i=0  \n",
    "    for mol in moldata:        \n",
    "       \n",
    "        desc_MolWt = Descriptors.MolWt(mol)\n",
    "        desc_MolLogP = Descriptors.MolLogP(mol)\n",
    "        desc_NumHDonors = Lipinski.NumHDonors(mol)\n",
    "        desc_NumHAcceptors = Lipinski.NumHAcceptors(mol)\n",
    "           \n",
    "        row = np.array([desc_MolWt,\n",
    "                        desc_MolLogP,\n",
    "                        desc_NumHDonors,\n",
    "                        desc_NumHAcceptors])   \n",
    "    \n",
    "        if(i==0):\n",
    "            baseData=row\n",
    "        else:\n",
    "            baseData=np.vstack([baseData, row])\n",
    "        i=i+1      \n",
    "    \n",
    "    columnNames=[\"MW\",\"LogP\",\"NumHDonors\",\"NumHAcceptors\"]   \n",
    "    descriptors = pd.DataFrame(data=baseData,columns=columnNames)\n",
    "    \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipinski = lipinski(df.canonical_smiles)\n",
    "df_lipinski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df,df_lipinski], axis=1)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pIC50(input):\n",
    "    pIC50 = []\n",
    "\n",
    "    for i in input['standard_value_norm']:\n",
    "        molar = i*(10**-9) # Converts nM to M\n",
    "        pIC50.append(-np.log10(molar))\n",
    "\n",
    "    input['pIC50'] = pIC50\n",
    "    x = input.drop('standard_value_norm', 1)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04863ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.standard_value.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log10( (10**-9)* 100000000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log10( (10**-9)* 10000000000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_value(input):\n",
    "    norm = []\n",
    "\n",
    "    for i in input['standard_value']:\n",
    "        if i > 100000000:\n",
    "          i = 100000000\n",
    "        norm.append(i)\n",
    "\n",
    "    input['standard_value_norm'] = norm\n",
    "    x = input.drop('standard_value', 1)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bdcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = norm_value(df_combined)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.standard_value_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2787fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pIC50(df_norm)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ee719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.pIC50.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d792f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('PARP1_04_bioactivity_data_3class_pIC50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992de72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the 'intermediate' bioactivity class\n",
    "df_2class = df_final[df_final['class']  != 'intermediate']\n",
    "df_2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2class.to_csv('PARP1_05_bioactivity_data_2class_pIC50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb919c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical\n",
    "mean_MW = df_2class.groupby('class')[\"MW\"].mean()\n",
    "SD_MW = df_2class.groupby('class')[\"MW\"].std()\n",
    "mean_LogP = df_2class.groupby('class')[\"LogP\"].mean()\n",
    "SD_LogP = df_2class.groupby('class')[\"LogP\"].std()\n",
    "mean_NumHDonors = df_2class.groupby('class')[\"NumHDonors\"].mean()\n",
    "SD_NumHDonors = df_2class.groupby('class')[\"NumHDonors\"].std()\n",
    "mean_NumHAcceptors = df_2class.groupby('class')[\"NumHAcceptors\"].mean()\n",
    "SD_NumHAcceptors = df_2class.groupby('class')[\"NumHAcceptors\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec84dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = [mean_MW,SD_MW,mean_LogP,SD_LogP,mean_NumHDonors,SD_NumHDonors,mean_NumHAcceptors,SD_NumHAcceptors]\n",
    "label=['meanMWac', 'meanMWin','SDMWac', 'SDMWin',\n",
    "     'meanLogPac', 'meanLogPin','SDLogPac','SDLogPin',\n",
    "     'meanNumHDonorsac','meanNumHDonorsin','SDNumHDonorsac','SDNumHDonorsin',\n",
    "    'meanNumHAcceptorsac', 'meanNumHAcceptorsin','SDNumHAcceptorsac','SDNumHAcceptorsin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4840f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_Ro5 = pd.concat(total, axis=0)\n",
    "Ro5 = pd.DataFrame(statistic_Ro5, columns=[\"stat\"])\n",
    "Ro5['label']= label\n",
    "Ro5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d598571",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ro5.to_csv(\"Ro5_stat.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a137ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style='ticks')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2426e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "sns.countplot(x='class', data=df_2class, edgecolor='black')\n",
    "\n",
    "plt.xlabel('bioactivity class', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Frequency', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.savefig('plot_bioactivity_class.tiff', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d793f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "sns.scatterplot(x='MW', y='LogP', data=df_2class, hue='class', size='pIC50', edgecolor='black', alpha=0.2)\n",
    "sns.set_style(\"whitegrid\", {\"ytick.major.size\": 100,\"xtick.major.size\": 2, 'grid.linestyle': 'solid'})\n",
    "\n",
    "plt.xlabel('MW', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('LogP', fontsize=14, fontweight='bold')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "\n",
    "plt.savefig('plot_MW_vs_LogP.tiff', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0086e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 5.5))\n",
    "\n",
    "sns.boxplot(x = 'class', y = 'pIC50', data = df_2class, medianprops=dict(color=\"black\", alpha=1, linewidth=2))\n",
    "\n",
    "plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('pIC50 value', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.savefig('plot_IC50.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81de89d",
   "metadata": {},
   "source": [
    "####  Statistical analysis | Mann-Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mannwhitney(descriptor, verbose=False):\n",
    "  # https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/\n",
    "  from numpy.random import seed\n",
    "  from numpy.random import randn\n",
    "  from scipy.stats import mannwhitneyu\n",
    "\n",
    "# seed the random number generator\n",
    "  seed(1)\n",
    "\n",
    "# actives and inactives\n",
    "  selection = [descriptor, 'class']\n",
    "  df = df_2class[selection]\n",
    "  active = df[df['class'] == 'active']\n",
    "  active = active[descriptor]\n",
    "\n",
    "  selection = [descriptor, 'class']\n",
    "  df = df_2class[selection]\n",
    "  inactive = df[df['class'] == 'inactive']\n",
    "  inactive = inactive[descriptor]\n",
    "\n",
    "# compare samples\n",
    "  stat, p = mannwhitneyu(active, inactive)\n",
    "  #print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "  alpha = 0.05\n",
    "  if p > alpha:\n",
    "    interpretation = 'Same distribution (fail to reject H0)'\n",
    "  else:\n",
    "    interpretation = 'Different distribution (reject H0)'\n",
    "  \n",
    "  results = pd.DataFrame({'Descriptor':descriptor,\n",
    "                          'Statistics':stat,\n",
    "                          'p':p,\n",
    "                          'alpha':alpha,\n",
    "                          'Interpretation':interpretation}, index=[0])\n",
    "  filename = 'mannwhitneyu_' + descriptor + '.csv'\n",
    "  results.to_csv(filename)\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitney('pIC50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statannotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440f5b2",
   "metadata": {},
   "source": [
    "#### MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 5.5))\n",
    "\n",
    "ax = sns.boxplot(x = 'class', y = 'MW', data = df_2class, showmeans = True, meanprops={\"marker\":\"o\",\"markerfacecolor\":\"white\", \n",
    "                       \"markeredgecolor\":\"black\",\"markersize\":\"8\"},\n",
    "                     medianprops=dict(color=\"black\", alpha=1, linewidth=3))\n",
    "ax.axhline(500, ls='--',c = 'black')\n",
    "ax.set(ylim=(100, 850))\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "plt.ylabel('MW', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.savefig('plot_MW.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitney('MW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce87473",
   "metadata": {},
   "source": [
    "#### LogP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e83f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 5.5))\n",
    "\n",
    "ax = sns.boxplot(x = 'class', y = 'LogP', data = df_2class, showmeans = True, meanprops={\"marker\":\"o\",\"markerfacecolor\":\"white\", \n",
    "                       \"markeredgecolor\":\"black\",\"markersize\":\"8\"},\n",
    "                     medianprops=dict(color=\"black\", alpha=1, linewidth=3))\n",
    "ax.axhline(5, ls='--',c = 'black')\n",
    "ax.set(ylim=(-6, 12))\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "plt.ylabel('LogP', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.savefig('plot_LogP.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitney('LogP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9573b1",
   "metadata": {},
   "source": [
    "#### NumHDonor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76346793",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 5.5))\n",
    "\n",
    "ax = sns.boxplot(x = 'class', y = 'NumHDonors', data = df_2class, \n",
    "                 showmeans = True, meanprops={\"marker\":\"o\",\"markerfacecolor\":\"white\", \n",
    "                       \"markeredgecolor\":\"black\",\"markersize\":\"8\"},\n",
    "                     medianprops=dict(color=\"black\", alpha=1, linewidth=3))\n",
    "ax.axhline(5, ls='--',c = 'black')\n",
    "ax.set(ylim=(-0.5,10.5))\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "plt.ylabel('NumHDonors', fontsize=14, fontweight='bold')\n",
    "               \n",
    "plt.savefig('plot_NumHDonors.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitney('NumHDonors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cbbda",
   "metadata": {},
   "source": [
    "#### NumHAcceptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 5.5))\n",
    "\n",
    "ax = sns.boxplot(x = 'class', y = 'NumHAcceptors', data = df_2class, showmeans = True, meanprops={\"marker\":\"o\",\"markerfacecolor\":\"white\", \n",
    "                       \"markeredgecolor\":\"black\",\"markersize\":\"8\"},\n",
    "                     medianprops=dict(color=\"black\", alpha=1, linewidth=3))\n",
    "ax.axhline(10, ls='--',c = 'black')\n",
    "ax.set(ylim=(0, 20))\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "plt.ylabel('NumHAcceptors', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.savefig('plot_NumHAcceptors.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80179e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhitney('NumHAcceptors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d469507",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbaac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r results.zip . -i *.csv *.tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed4b55",
   "metadata": {},
   "source": [
    "### 03_Molecular descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef22cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install m2-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget.download('https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/AtomPairs2DFingerprintCount.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/AtomPairs2DFingerprinter.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/EStateFingerprinter.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/ExtendedFingerprinter.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/Fingerprinter.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/GraphOnlyFingerprinter.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/KlekotaRothFingerprintCount.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/KlekotaRothFingerprinter.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/MACCSFingerprinter.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/PubchemFingerprinter.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/SubstructureFingerprintCount.sh')\n",
    "wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/SubstructureFingerprinter.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipObj = ZipFile(\"padel.zip\", \"r\")\n",
    "zipObj.extractall()\n",
    "zipObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PARP1_05_bioactivity_data_2class_pIC50.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d82e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='class',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('PARP1_05_bioactivity_data_2class_pIC50_sort_class.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = ['canonical_smiles','molecule_chembl_id']\n",
    "df_selection = df[selection]\n",
    "df_selection.to_csv('molecule_pos_neg_sort.smi', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f627c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat molecule_pos_neg_sort.smi | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e85533",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat molecule_pos_neg_sort.smi | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d831ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat AtomPairs2DFingerprintCount.sh\n",
    "!bash AtomPairs2DFingerprintCount.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04449348",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat AtomPairs2DFingerprinter.sh\n",
    "!bash AtomPairs2DFingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat EStateFingerprinter.sh\n",
    "!bash EStateFingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ExtendedFingerprinter.sh\n",
    "!bash ExtendedFingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat Fingerprinter.sh\n",
    "!bash Fingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916619c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat GraphOnlyFingerprinter.sh\n",
    "!bash GraphOnlyFingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f37a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat KlekotaRothFingerprintCount.sh\n",
    "!bash KlekotaRothFingerprintCount.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat KlekotaRothFingerprinter.sh\n",
    "!bash KlekotaRothFingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat MACCSFingerprinter.sh\n",
    "!bash MACCSFingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat PubchemFingerprinter.sh\n",
    "!bash PubchemFingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd9ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat SubstructureFingerprintCount.sh\n",
    "!bash SubstructureFingerprintCount.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55735887",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat SubstructureFingerprinter.sh\n",
    "!bash SubstructureFingerprinter.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67316d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_AFC = pd.read_csv('descriptors_output_AtomPairs2DFingerprintCount.csv')\n",
    "df_x_AF = pd.read_csv('descriptors_output_AtomPairs2DFingerprinter.csv')\n",
    "df_x_ESF = pd.read_csv('descriptors_output_EStateFingerprinter.csv')\n",
    "df_x_EXF = pd.read_csv('descriptors_output_ExtendedFingerprinter.csv')\n",
    "df_x_F = pd.read_csv('descriptors_output_Fingerprinter.csv')\n",
    "df_x_GF = pd.read_csv('descriptors_output_GraphOnlyFingerprinter.csv')\n",
    "df_x_KRFC = pd.read_csv('descriptors_output_KlekotaRothFingerprintCount.csv')\n",
    "df_x_KRF = pd.read_csv('descriptors_output_KlekotaRothFingerprinter.csv')\n",
    "df_x_MF = pd.read_csv('descriptors_output_MACCSFingerprinter.csv')\n",
    "df_x_PF = pd.read_csv('descriptors_output_PubchemFingerprinter.csv')\n",
    "df_x_SFC = pd.read_csv('descriptors_output_SubstructureFingerprintCount.csv')\n",
    "df_x_SF = pd.read_csv('descriptors_output_SubstructureFingerprinter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44433cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_AFC = df_x_AFC.drop(columns=['Name'])\n",
    "df_x_AF = df_x_AF.drop(columns=['Name'])\n",
    "df_x_ESF = df_x_ESF.drop(columns=['Name'])\n",
    "df_x_EXF = df_x_EXF.drop(columns=['Name'])\n",
    "df_x_F = df_x_F.drop(columns=['Name'])\n",
    "df_x_GF = df_x_GF.drop(columns=['Name'])\n",
    "df_x_KRFC = df_x_KRFC.drop(columns=['Name'])\n",
    "df_x_KRF  = df_x_KRF.drop(columns=['Name'])\n",
    "df_x_MF = df_x_MF.drop(columns=['Name'])\n",
    "df_x_PF = df_x_PF.drop(columns=['Name'])\n",
    "df_x_SFC = df_x_SFC.drop(columns=['Name'])\n",
    "df_x_SF = df_x_SF.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_AFC = df['class']\n",
    "df_y_AF = df['class']\n",
    "df_y_ESF = df['class']\n",
    "df_y_EXF = df['class']\n",
    "df_y_F = df['class']\n",
    "df_y_GF = df['class']\n",
    "df_y_KRFC = df['class']\n",
    "df_y_KRF  = df['class']\n",
    "df_y_MF = df['class']\n",
    "df_y_PF = df['class']\n",
    "df_y_SFC = df['class']\n",
    "df_y_SF = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd05a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_AFC = pd.concat([df_x_AFC,df_y_AFC], axis=1)\n",
    "dataset_AF = pd.concat([df_x_AF,df_y_AF], axis=1)\n",
    "dataset_ESF = pd.concat([df_x_ESF,df_y_ESF], axis=1)\n",
    "dataset_EXF = pd.concat([df_x_EXF,df_y_EXF], axis=1)\n",
    "dataset_F = pd.concat([df_x_F,df_y_F], axis=1)\n",
    "dataset_GF = pd.concat([df_x_GF,df_y_GF], axis=1)\n",
    "dataset_KRFC = pd.concat([df_x_KRFC,df_y_KRFC], axis=1)\n",
    "dataset_KRF  = pd.concat([df_x_KRF,df_y_KRF], axis=1)\n",
    "dataset_MF = pd.concat([df_x_MF,df_y_MF], axis=1)\n",
    "dataset_PF = pd.concat([df_x_PF,df_y_PF], axis=1)\n",
    "dataset_SFC = pd.concat([df_x_SFC,df_y_SFC], axis=1)\n",
    "dataset_SF = pd.concat([df_x_SF,df_y_SF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_AFC.to_csv('PARP1_06_bioactivity_data_2class_IC50_AFC.csv', index=False)\n",
    "dataset_AF.to_csv('PARP1_06_bioactivity_data_2class_IC50_AF.csv', index=False)\n",
    "dataset_ESF.to_csv('PARP1_06_bioactivity_data_2class_IC50_ESF.csv', index=False)\n",
    "dataset_EXF.to_csv('PARP1_06_bioactivity_data_2class_IC50_EXF.csv', index=False)\n",
    "dataset_F.to_csv('PARP1_06_bioactivity_data_2class_IC50_F.csv', index=False)\n",
    "dataset_GF.to_csv('PARP1_06_bioactivity_data_2class_IC50_GF.csv', index=False)\n",
    "dataset_KRFC.to_csv('PARP1_06_bioactivity_data_2class_IC50_KRFC.csv', index=False)\n",
    "dataset_KRF.to_csv('PARP1_06_bioactivity_data_2class_IC50_KRF.csv', index=False)\n",
    "dataset_MF.to_csv('PARP1_06_bioactivity_data_2class_IC50_MF.csv', index=False)\n",
    "dataset_PF.to_csv('PARP1_06_bioactivity_data_2class_IC50_PF.csv', index=False)\n",
    "dataset_SFC.to_csv('PARP1_06_bioactivity_data_2class_IC50_SFC.csv', index=False)\n",
    "dataset_SF.to_csv('PARP1_06_bioactivity_data_2class_IC50_SF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aafb99",
   "metadata": {},
   "source": [
    "### Read in fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab41ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github')\n",
    "df_x_AFC = pd.read_csv('descriptors_output_AtomPairs2DFingerprintCount.csv')\n",
    "df_x_AF = pd.read_csv('descriptors_output_AtomPairs2DFingerprinter.csv')\n",
    "df_x_ESF = pd.read_csv('descriptors_output_EStateFingerprinter.csv')\n",
    "df_x_EXF = pd.read_csv('descriptors_output_ExtendedFingerprinter.csv')\n",
    "df_x_F = pd.read_csv('descriptors_output_Fingerprinter.csv')\n",
    "df_x_GF = pd.read_csv('descriptors_output_GraphOnlyFingerprinter.csv')\n",
    "df_x_KRFC = pd.read_csv('descriptors_output_KlekotaRothFingerprintCount.csv')\n",
    "df_x_KRF = pd.read_csv('descriptors_output_KlekotaRothFingerprinter.csv')\n",
    "df_x_MF = pd.read_csv('descriptors_output_MACCSFingerprinter.csv')\n",
    "df_x_PF = pd.read_csv('descriptors_output_PubchemFingerprinter.csv')\n",
    "df_x_SFC = pd.read_csv('descriptors_output_SubstructureFingerprintCount.csv')\n",
    "df_x_SF = pd.read_csv('descriptors_output_SubstructureFingerprinter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('PARP1_05_bioactivity_data_2class_pIC50_sort_class.csv')\n",
    "df =  df.iloc[:, 1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('fingerprint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d414f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('fingerprint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ab235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_AFC.to_csv('AtomPairs2DCount.csv', index=False)\n",
    "df_x_AF.to_csv('AtomPairs2D.csv', index=False)\n",
    "df_x_ESF.to_csv('EState.csv', index=False)\n",
    "df_x_EXF.to_csv('CDKextended.csv', index=False)\n",
    "df_x_F.to_csv('CDK.csv', index=False)\n",
    "df_x_GF.to_csv('CDKgraphonly.csv', index=False)\n",
    "df_x_KRFC.to_csv('KlekotaRothCount.csv', index=False)\n",
    "df_x_KRF.to_csv('KlekotaRoth.csv', index=False)\n",
    "df_x_MF.to_csv('MACCS.csv', index=False)\n",
    "df_x_PF.to_csv('PubChem.csv', index=False)\n",
    "df_x_SFC.to_csv('SubstructureCount.csv', index=False)\n",
    "df_x_SF.to_csv('Substructure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a27b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables to house fingerprint descriptors as DataFrames\n",
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github')\n",
    "\n",
    "FP_list = ['AtomPairs2DCount',\n",
    " 'AtomPairs2D',\n",
    " 'EState',\n",
    " 'CDKextended',\n",
    " 'CDK',\n",
    " 'CDKgraphonly',\n",
    " 'KlekotaRothCount',\n",
    " 'KlekotaRoth',\n",
    " 'MACCS',\n",
    " 'PubChem',\n",
    " 'SubstructureCount',\n",
    " 'Substructure']\n",
    "\n",
    "for i in FP_list:\n",
    "  fp = f'fingerprint/{i}.csv'\n",
    "  descriptors = pd.read_csv(fp, index_col=False)\n",
    "  exec(i + '= descriptors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1eba55",
   "metadata": {},
   "source": [
    "### 04_Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d12c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f428d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0379d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Model performance metric\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d8a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = {'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42),\n",
    "                  'GradientBoostingClassifier': GradientBoostingClassifier(random_state=42),\n",
    "                  'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "                  'MLPClassifier': MLPClassifier(random_state=42),\n",
    "                  'RandomForestClassifier': RandomForestClassifier(random_state=42),\n",
    "                  'SVC': SVC(kernel='rbf', random_state=42),#remove class_weight\n",
    "                  'XGBClassifier': XGBClassifier(random_state=42),\n",
    "                  'LGBMClassifier': LGBMClassifier(random_state=42),\n",
    "                  'ExtraTreesClassifier': ExtraTreesClassifier(random_state=42),\n",
    "                  'GaussianProcessClassifier': GaussianProcessClassifier(random_state=42),\n",
    "                  'GaussianNB': GaussianNB(),\n",
    "                  'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539755fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balancing\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import pickle\n",
    "\n",
    "def remove_low_variance(input_data, threshold=0.1):\n",
    "    selection = VarianceThreshold(threshold)\n",
    "    selection.fit(input_data)\n",
    "    return input_data[input_data.columns[selection.get_support(indices=True)]]\n",
    "\n",
    "def model_building(features_df, bioactivity_class, classifier, balancing):\n",
    "  \n",
    "  # Preparing X and y\n",
    "  df = eval(features_df)\n",
    "  X = df.drop('Name', axis=1)\n",
    "  y = bioactivity_class\n",
    "  y = pd.Series(y)\n",
    "\n",
    "  def target_encode(val):\n",
    "    target_mapper = {'inactive':0, 'active':1}\n",
    "    return target_mapper[val]\n",
    "\n",
    "  y = y.apply(target_encode)\n",
    "\n",
    "  # Remove low variance features\n",
    "  X2 = remove_low_variance(X, threshold=0.01)\n",
    "  X2.to_csv(f'{balancing}_{features_df}_removed_low_variance_0.1.csv', index=False)\n",
    "  \n",
    "  # Data splitting\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.2, random_state=42)\n",
    "  X_train.to_csv(f'{balancing}_{features_df}_X_train.csv', index=False)\n",
    "  y_train.to_csv(f'{balancing}_{features_df}_y_train.csv', index=False)\n",
    "  X_test.to_csv(f'{balancing}_{features_df}_X_test.csv', index=False)\n",
    "  y_test.to_csv(f'{balancing}_{features_df}_y_test.csv', index=False)\n",
    "\n",
    "  # Oversampling\n",
    "  if balancing == 'oversampling':\n",
    "    ros = RandomOverSampler(sampling_strategy=\"not majority\") # String\n",
    "    X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "    X_train = X_train_ros\n",
    "    y_train = y_train_ros\n",
    "  if balancing == 'undersampling':\n",
    "    rus = RandomUnderSampler(sampling_strategy=1) # Numerical value\n",
    "    X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "    X_train = X_train_rus\n",
    "    y_train = y_train_rus\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "  # Model building\n",
    "  model = classifier_list[classifier]\n",
    "  model.fit(X_train, y_train)\n",
    "  # Saving the model\n",
    "  pickle.dump(model, open(f'{balancing}_{features_df}_{classifier}.pkl', 'wb'))\n",
    "\n",
    "  # Apply model to make prediction\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  \n",
    "  # Building a CV model\n",
    "  model_cv = classifier_list[classifier]\n",
    "  #cv = cross_validate(model_cv, X_train, y_train, cv=5, scoring=make_scorer(matthews_corrcoef))\n",
    "  cv_scoring = {'Ac': 'accuracy', 'Sn': make_scorer(recall_score), 'Sp': make_scorer(recall_score, pos_label=0), 'MCC': make_scorer(matthews_corrcoef)}\n",
    "  cv = cross_validate(model_cv, X_train, y_train, cv=5, scoring=cv_scoring)\n",
    "\n",
    "  # Calculating model performance\n",
    "  ac_train = accuracy_score(y_train, y_train_pred)\n",
    "  ac_test = accuracy_score(y_test, y_test_pred)\n",
    "  ac_cv = cv['test_Ac'].mean()\n",
    "\n",
    "  sn_train = recall_score(y_train, y_train_pred)\n",
    "  sn_test = recall_score(y_test, y_test_pred)\n",
    "  sn_cv = cv['test_Sn'].mean()\n",
    "\n",
    "  sp_train = recall_score(y_train, y_train_pred, pos_label=0)\n",
    "  sp_test = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "  sp_cv = cv['test_Sp'].mean()\n",
    "\n",
    "  mcc_train = matthews_corrcoef(y_train, y_train_pred)\n",
    "  mcc_test = matthews_corrcoef(y_test, y_test_pred)\n",
    "  mcc_cv = cv['test_MCC'].mean()\n",
    "  \n",
    "  # Preparing performance summary table\n",
    "  model_name = pd.Series([classifier], name='Algorithm')\n",
    "\n",
    "  ac_train_series = pd.Series(ac_train, name='Ac_train')\n",
    "  ac_test_series = pd.Series(ac_test, name='Ac_test')\n",
    "  ac_cv_series = pd.Series(ac_cv, name='Ac_cv')\n",
    "\n",
    "  sn_train_series = pd.Series(sn_train, name='Sn_train')\n",
    "  sn_test_series = pd.Series(sn_test, name='Sn_test')\n",
    "  sn_cv_series = pd.Series(sn_cv, name='Sn_cv')\n",
    "\n",
    "  sp_train_series = pd.Series(sp_train, name='Sp_train')\n",
    "  sp_test_series = pd.Series(sp_test, name='Sp_test')\n",
    "  sp_cv_series = pd.Series(sp_cv, name='Sp_cv')\n",
    "\n",
    "  mcc_train_series = pd.Series(mcc_train, name='MCC_train')\n",
    "  mcc_cv_series = pd.Series(mcc_cv, name='MCC_cv')\n",
    "  mcc_test_series = pd.Series(mcc_test, name='MCC_test')\n",
    "\n",
    "#change the code -- recheck\n",
    "  performance_metrics = pd.concat([model_name,\n",
    "                                   ac_train_series, sn_train_series, sp_train_series, mcc_train_series,\n",
    "                                   ac_cv_series, sn_cv_series, sp_cv_series,  mcc_cv_series,\n",
    "                                   ac_test_series, sn_test_series, sp_test_series, mcc_test_series], axis=1)                           \n",
    "  performance_metrics['MCC_train_cv'] = abs(performance_metrics['MCC_train'] - performance_metrics['MCC_cv'])\n",
    "  performance_metrics['MCC_train_test'] = abs(performance_metrics['MCC_train'] - performance_metrics['MCC_test'])\n",
    "\n",
    "  return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through both the Classifier and Fingerprint lists\n",
    "df_list = []\n",
    "\n",
    "for i in classifier_list:\n",
    "  for j in FP_list:\n",
    "    print(j, i)\n",
    "    classifier = model_building(j, df['class'], i, 'normal')\n",
    "    classifier['Fingerprint'] = j\n",
    "    # Reorder last column to be first column\n",
    "    cols = classifier.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1] \n",
    "    classifier = classifier[cols]\n",
    "    # Append DataFrame to list\n",
    "    df_list.append(classifier)\n",
    "\n",
    "# Combine DataFrame from list\n",
    "df_final_normal = pd.concat(df_list)\n",
    "df_final_normal.sort_values(by=['Fingerprint'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through both the Classifier and Fingerprint lists\n",
    "df_list = []\n",
    "\n",
    "for i in classifier_list:\n",
    "  for j in FP_list:\n",
    "    print(j, i)\n",
    "    classifier = model_building(j, df['class'], i, 'oversampling')\n",
    "    classifier['Fingerprint'] = j\n",
    "    # Reorder last column to be first column\n",
    "    cols = classifier.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1] \n",
    "    classifier = classifier[cols]\n",
    "    # Append DataFrame to list\n",
    "    df_list.append(classifier)\n",
    "\n",
    "# Combine DataFrame from list\n",
    "df_final_oversampling = pd.concat(df_list)\n",
    "df_final_oversampling.sort_values(by=['Fingerprint'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694645fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through both the Classifier and Fingerprint lists\n",
    "df_list = []\n",
    "\n",
    "for i in classifier_list:\n",
    "  for j in FP_list:\n",
    "    print(j, i)\n",
    "    classifier = model_building(j, df['class'], i, 'undersampling')\n",
    "    classifier['Fingerprint'] = j\n",
    "    # Reorder last column to be first column\n",
    "    cols = classifier.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1] \n",
    "    classifier = classifier[cols]\n",
    "    # Append DataFrame to list\n",
    "    df_list.append(classifier)\n",
    "\n",
    "# Combine DataFrame from list\n",
    "df_final_undersampling = pd.concat(df_list)\n",
    "df_final_undersampling.sort_values(by=['Fingerprint'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059825c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced data\n",
    "df_final_normal.to_csv('normal_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_oversampling.to_csv('oversampling_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229381ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_undersampling.to_csv('undersampling_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "! zip PARP1_normal_models_pkl.zip normal*.pkl\n",
    "! zip PARP1_normal_lowvarianceremoved_datasplit.zip normal*.csv\n",
    "! zip PARP1_oversampling_models_pkl.zip oversampling*.pkl\n",
    "! zip PARP1_oversampling_lowvarianceremoved_datasplit.zip oversampling*.csv\n",
    "! zip PARP1_undersampling_models_pkl.zip undersampling*.pkl\n",
    "! zip PARP1_undersampling_lowvarianceremoved_datasplit.zip undersampling*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd77ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ZIP\n",
    "! mv *.zip ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66be9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir results\n",
    "! mv *results.csv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm normal*.pkl normal*.csv oversampling*.pkl oversampling*.csv undersampling*.pkl undersampling*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feba0a8",
   "metadata": {},
   "source": [
    "### 05_Post-Model Analysis\n",
    "#### restart kernel to clear previous outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = \"PARP1_normal_lowvarianceremoved_datasplit.zip\"\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "    \n",
    "    # extracting specific file\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extract('normal_results.csv')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = \"PARP1_oversampling_lowvarianceremoved_datasplit.zip\"\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "    \n",
    "    # extracting specific file\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extract('oversampling_results.csv')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab343e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = \"PARP1_undersampling_lowvarianceremoved_datasplit.zip\"\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "    \n",
    "    # extracting specific file\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extract('undersampling_results.csv')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a7a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('normal_results.csv')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "df2 = df.copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10778599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for making Heatmap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def make_heatmap(score):\n",
    "  # Shaping the data\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  # Making the Heatmap\n",
    "  fig, ax = plt.subplots()\n",
    "  im = ax.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "  #im = ax.imshow(z, cmap='cool')\n",
    "\n",
    "  # Show all ticks\n",
    "  ax.set_xticks(np.arange(len(x)))\n",
    "  ax.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax.set_xticklabels(x)\n",
    "  ax.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "  # Add colorbar\n",
    "  divider = make_axes_locatable(ax)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im, cax=cax)\n",
    "\n",
    "  fig.set_size_inches(9, 9)\n",
    "  fig.tight_layout()\n",
    "  #plt.savefig(f'{score}.pdf')\n",
    "  plt.savefig(f'{score}.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('normal_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ea7a7",
   "metadata": {},
   "source": [
    "#### MCC for Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26680b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\normal_results')\n",
    "make_heatmap('MCC_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b31b01",
   "metadata": {},
   "source": [
    "#### MCC for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e6a9b",
   "metadata": {},
   "source": [
    "#### MCC for CV set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d012563",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for making Heatmap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def make_heatmap_panel_plot():\n",
    "  # Shaping the data\n",
    "\n",
    "  # Making the Heatmap\n",
    "  fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "  #im = ax.imshow(z, cmap='cool')\n",
    "\n",
    "# ax1\n",
    "  # Data\n",
    "  score1 = 'MCC_train'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score1]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score1]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im1 = ax1.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "  \n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax1)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im1, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax1.set_xticks(np.arange(len(x)))\n",
    "  ax1.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax1.set_xticklabels(x)\n",
    "  ax1.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax1.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "# ax2\n",
    "  # Data\n",
    "  score2 = 'MCC_cv'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score2]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score2]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im2 = ax2.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "    \n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax2)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im2, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax2.set_xticks(np.arange(len(x)))\n",
    "  ax2.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax2.set_xticklabels(x)\n",
    "  ax2.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax2.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax2.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "# ax3\n",
    "  # Data\n",
    "  score3 = 'MCC_test'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score3]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score3]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im3 = ax3.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "\n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax3)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im3, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax3.set_xticks(np.arange(len(x)))\n",
    "  ax3.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax3.set_xticklabels(x)\n",
    "  ax3.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax3.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax3.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "\n",
    "  # Y tick labels\n",
    "  ax2.yaxis.set_ticklabels([])\n",
    "  ax3.yaxis.set_ticklabels([])\n",
    "\n",
    "  # Sub-plot title\n",
    "  ax1.set_title('Training set', fontsize=14, fontweight='bold', pad=15) # Training set\n",
    "  ax2.set_title('CV set', fontsize=14, fontweight='bold', pad=15) # CV set\n",
    "  ax3.set_title('Test set', fontsize=14, fontweight='bold', pad=15) # Test set\n",
    "\n",
    "  # Axes labels\n",
    "  ax1.set_ylabel('Fingerprints', fontweight='bold', fontsize=14, labelpad=15)\n",
    "  ax2.set_xlabel('MCC', fontweight='bold', fontsize=14, labelpad=15)\n",
    "     \n",
    "  fig.set_size_inches(18, 10.5)\n",
    "  fig.tight_layout()\n",
    "  #plt.savefig('Fig_Heatmap_Model_Performance.pdf')\n",
    "  plt.savefig('Fig_Heatmap_Model_Performance.tiff')\n",
    "\n",
    "make_heatmap_panel_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e63fd",
   "metadata": {},
   "source": [
    "#### MCC of Training minus MCC of CV set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_train_cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0acd50",
   "metadata": {},
   "source": [
    "#### MCC of Training minus MCC of Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d24e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_train_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fee62d",
   "metadata": {},
   "source": [
    "#### Oversampling_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21139d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')\n",
    "df = pd.read_csv('oversampling_results.csv')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "df2 = df.copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('oversampling_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\oversampling_results')\n",
    "make_heatmap('MCC_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c02861",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dbb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for making Heatmap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def make_heatmap_panel_plot():\n",
    "  # Shaping the data\n",
    "\n",
    "  # Making the Heatmap\n",
    "  fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "  #im = ax.imshow(z, cmap='cool')\n",
    "\n",
    "# ax1\n",
    "  # Data\n",
    "  score1 = 'MCC_train'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score1]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score1]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im1 = ax1.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "  \n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax1)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im1, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax1.set_xticks(np.arange(len(x)))\n",
    "  ax1.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax1.set_xticklabels(x)\n",
    "  ax1.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax1.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "# ax2\n",
    "  # Data\n",
    "  score2 = 'MCC_cv'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score2]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score2]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im2 = ax2.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "    \n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax2)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im2, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax2.set_xticks(np.arange(len(x)))\n",
    "  ax2.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax2.set_xticklabels(x)\n",
    "  ax2.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax2.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax2.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "# ax3\n",
    "  # Data\n",
    "  score3 = 'MCC_test'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score3]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score3]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im3 = ax3.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "\n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax3)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im3, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax3.set_xticks(np.arange(len(x)))\n",
    "  ax3.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax3.set_xticklabels(x)\n",
    "  ax3.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax3.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax3.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "\n",
    "  # Y tick labels\n",
    "  ax2.yaxis.set_ticklabels([])\n",
    "  ax3.yaxis.set_ticklabels([])\n",
    "\n",
    "  # Sub-plot title\n",
    "  ax1.set_title('Training set', fontsize=14, fontweight='bold', pad=15) # Training set\n",
    "  ax2.set_title('CV set', fontsize=14, fontweight='bold', pad=15) # CV set\n",
    "  ax3.set_title('Test set', fontsize=14, fontweight='bold', pad=15) # Test set\n",
    "\n",
    "  # Axes labels\n",
    "  ax1.set_ylabel('Fingerprints', fontweight='bold', fontsize=14, labelpad=15)\n",
    "  ax2.set_xlabel('MCC', fontweight='bold', fontsize=14, labelpad=15)\n",
    "     \n",
    "  fig.set_size_inches(18, 10.5)\n",
    "  fig.tight_layout()\n",
    "  #plt.savefig('Fig_Heatmap_Model_Performance.pdf')\n",
    "  plt.savefig('Fig_Heatmap_Model_Performance.tiff')\n",
    "\n",
    "make_heatmap_panel_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8185fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_train_cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_train_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e355b6",
   "metadata": {},
   "source": [
    "#### Undersampling_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba54953",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')\n",
    "df = pd.read_csv('undersampling_results.csv')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "df2 = df.copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('undersampling_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52daeb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\undersampling_results')\n",
    "make_heatmap('MCC_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763514bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for making Heatmap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def make_heatmap_panel_plot():\n",
    "  # Shaping the data\n",
    "\n",
    "  # Making the Heatmap\n",
    "  fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "  #im = ax.imshow(z, cmap='cool')\n",
    "\n",
    "# ax1\n",
    "  # Data\n",
    "  score1 = 'MCC_train'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score1]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score1]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im1 = ax1.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "  \n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax1)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im1, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax1.set_xticks(np.arange(len(x)))\n",
    "  ax1.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax1.set_xticklabels(x)\n",
    "  ax1.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax1.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "# ax2\n",
    "  # Data\n",
    "  score2 = 'MCC_cv'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score2]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score2]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im2 = ax2.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "    \n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax2)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im2, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax2.set_xticks(np.arange(len(x)))\n",
    "  ax2.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax2.set_xticklabels(x)\n",
    "  ax2.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax2.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax2.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "# ax3\n",
    "  # Data\n",
    "  score3 = 'MCC_test'\n",
    "  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score3]], axis=1)\n",
    "  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n",
    "  grid_reset = grid_contour.reset_index()\n",
    "  grid_reset.columns = ['Fingerprint', 'Algorithm', score3]\n",
    "  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n",
    "  x = grid_pivot.columns.levels[1].values\n",
    "  y = grid_pivot.index.values\n",
    "  z = np.round(grid_pivot.values, 2)\n",
    "\n",
    "  im3 = ax3.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n",
    "\n",
    "  #add color bar\n",
    "  divider = make_axes_locatable(ax3)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "  plt.colorbar(im3, cax=cax)\n",
    "\n",
    "  # Show all ticks\n",
    "  ax3.set_xticks(np.arange(len(x)))\n",
    "  ax3.set_yticks(np.arange(len(y)))\n",
    "  # Label all ticks with list entries\n",
    "  ax3.set_xticklabels(x)\n",
    "  ax3.set_yticklabels(y)\n",
    "\n",
    "  # Rotate the tick labels and set their alignment.\n",
    "  plt.setp(ax3.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(y)):\n",
    "      for j in range(len(x)):\n",
    "          text = ax3.text(j, i, z[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "\n",
    "  # Y tick labels\n",
    "  ax2.yaxis.set_ticklabels([])\n",
    "  ax3.yaxis.set_ticklabels([])\n",
    "\n",
    "  # Sub-plot title\n",
    "  ax1.set_title('Training set', fontsize=14, fontweight='bold', pad=15) # Training set\n",
    "  ax2.set_title('CV set', fontsize=14, fontweight='bold', pad=15) # CV set\n",
    "  ax3.set_title('Test set', fontsize=14, fontweight='bold', pad=15) # Test set\n",
    "\n",
    "  # Axes labels\n",
    "  ax1.set_ylabel('Fingerprints', fontweight='bold', fontsize=14, labelpad=15)\n",
    "  ax2.set_xlabel('MCC', fontweight='bold', fontsize=14, labelpad=15)\n",
    "     \n",
    "  fig.set_size_inches(18, 10.5)\n",
    "  fig.tight_layout()\n",
    "  #plt.savefig('Fig_Heatmap_Model_Performance.pdf')\n",
    "  plt.savefig('Fig_Heatmap_Model_Performance.tiff')\n",
    "\n",
    "make_heatmap_panel_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9990be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_train_cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7febc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap('MCC_train_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68d02c",
   "metadata": {},
   "source": [
    "### 06_Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1dcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be36efb",
   "metadata": {},
   "source": [
    "#### Select pubchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ac270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = \"PARP1_oversampling_models_pkl.zip\"\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "    \n",
    "    # extracting specific file\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extract('oversampling_PubChem_RandomForestClassifier.pkl')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = \"PARP1_oversampling_lowvarianceremoved_datasplit.zip\"\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "    \n",
    "    # extracting specific file\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extract('oversampling_PubChem_X_train.csv')\n",
    "    zip.extract('oversampling_PubChem_y_train.csv')\n",
    "    zip.extract('oversampling_PubChem_X_test.csv')\n",
    "    zip.extract('oversampling_PubChem_y_test.csv')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e164b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "X_train = pd.read_csv('oversampling_PubChem_X_train.csv')\n",
    "y_train = pd.read_csv('oversampling_PubChem_y_train.csv')\n",
    "X_test = pd.read_csv('oversampling_PubChem_X_test.csv')\n",
    "y_test = pd.read_csv('oversampling_PubChem_y_test.csv')\n",
    "\n",
    "load_model = pickle.load(open('oversampling_PubChem_RandomForestClassifier.pkl', 'rb'))\n",
    "\n",
    "X_train_pred = load_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a426320",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([pd.Series(X_train.columns, name='Features'), pd.Series(load_model.feature_importances_, name='Gini')], axis=1 )\n",
    "features.sort_values(by='Gini', ascending=False, inplace=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('feature_Gini_oversampling_PubChem_RandomForestClassifier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b376218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,8))\n",
    "plt.barh(features.Features, features.Gini, color='#7CAE00', edgecolor='black', align='center', alpha=0.8)\n",
    "plt.ylim(-0.5,19.5)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlabel('Gini Index', fontsize=14, fontweight='bold', labelpad=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlim(0, 0.025)\n",
    "\n",
    "plt.margins(0.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('Barplot_feature_importance_oversampling_PubChem_RandomForestClassifier.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48f3bc",
   "metadata": {},
   "source": [
    "### 07_PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd28fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA modeling\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Data scaling\n",
    "X_train = scale(X_train)\n",
    "X_test = scale(X_test)\n",
    "\n",
    "# Build PCA model\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "pca.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45dd1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')\n",
    "os.mkdir('PCA_scores')\n",
    "os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\PCA_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c05af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Screen plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.savefig('Screen plot.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PC scores train\n",
    "scores_train = pca.transform(X_train)\n",
    "scores_df_train = pd.DataFrame(scores_train)\n",
    "scores_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PC scores test\n",
    "scores_test = pca.transform(X_test)\n",
    "scores_df_test = pd.DataFrame(scores_test)\n",
    "scores_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_train.to_csv('scores_df_train.csv')\n",
    "scores_df_test.to_csv('scores_df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversee max min\n",
    "train_max = scores_df_train.values.max()\n",
    "train_min = scores_df_train.values.min()\n",
    "test_max = scores_df_test.values.max()\n",
    "test_min = scores_df_test.values.min()\n",
    "print(train_max,train_min)\n",
    "print(test_max,test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9a67e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA scores plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "\n",
    "# PC1 vs PC2\n",
    "ax1.scatter(x=scores_df_train[0], y=scores_df_train[1], c=\"#7CAE00\", alpha=0.2, edgecolor='black', label='train') #green\n",
    "ax1.scatter(x=scores_df_test[0], y=scores_df_test[1], c=\"#f25555\", alpha=0.2, edgecolor='black', label='test') #red\n",
    "\n",
    "# PC1 vs PC3\n",
    "ax2.scatter(x=scores_df_train[0], y=scores_df_train[2], c=\"#7CAE00\", alpha=0.2, edgecolor='black', label='train')\n",
    "ax2.scatter(x=scores_df_test[0], y=scores_df_test[2], c=\"#f25555\", alpha=0.2, edgecolor='black', label='test')\n",
    "\n",
    "# PC2 vs PC3\n",
    "ax3.scatter(x=scores_df_train[1], y=scores_df_train[2], c=\"#7CAE00\", alpha=0.2, edgecolor='black', label='train')\n",
    "ax3.scatter(x=scores_df_test[1], y=scores_df_test[2], c=\"#f25555\", alpha=0.2, edgecolor='black', label='test')\n",
    "\n",
    "# X tick limits\n",
    "ax1.set_xlim(-15, 20)\n",
    "ax2.set_xlim(-15, 20)\n",
    "ax3.set_xlim(-18, 20)\n",
    "\n",
    "# Y tick labels\n",
    "ax1.set_ylim(-18, 20)\n",
    "ax2.set_ylim(-12, 35)\n",
    "ax3.set_ylim(-12, 35)\n",
    "\n",
    "# Axes labels\n",
    "ax1.set_xlabel('PC1', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('PC2', fontsize=14, fontweight='bold', labelpad = -2)\n",
    "ax1.grid()\n",
    "\n",
    "ax2.set_xlabel('PC1', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('PC3', fontsize=14, fontweight='bold', labelpad = -2)\n",
    "ax2.grid()\n",
    "\n",
    "ax3.set_xlabel('PC2', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('PC3', fontsize=14, fontweight='bold', labelpad = -2)\n",
    "ax3.grid()\n",
    "\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('PCA_scores.tiff')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chemoinf]",
   "language": "python",
   "name": "conda-env-chemoinf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
