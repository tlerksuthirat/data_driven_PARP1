{"cells":[{"cell_type":"markdown","id":"c88acee6","metadata":{"id":"c88acee6"},"source":["### Derived from 2022-01-26-PARP1-TL"]},{"cell_type":"markdown","id":"62069880","metadata":{"id":"62069880"},"source":["### 01_Retrieve PARP1 from ChEMBL"]},{"cell_type":"code","execution_count":null,"id":"2929cfa8","metadata":{"id":"2929cfa8"},"outputs":[],"source":["pip install chembl_webresource_client"]},{"cell_type":"code","execution_count":null,"id":"bda51e84","metadata":{"id":"bda51e84"},"outputs":[],"source":["import pandas as pd\n","from chembl_webresource_client.new_client import new_client\n","import os\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"9232ec83","metadata":{"id":"9232ec83"},"outputs":[],"source":["target = new_client.target\n","target_query = target.search('PARP1')\n","targets = pd.DataFrame.from_dict(target_query)\n","targets"]},{"cell_type":"code","execution_count":null,"id":"4abc9a97","metadata":{"id":"4abc9a97"},"outputs":[],"source":["selected_target = targets.target_chembl_id[0]\n","selected_target"]},{"cell_type":"code","execution_count":null,"id":"68718556","metadata":{"id":"68718556"},"outputs":[],"source":["ac = new_client.activity\n","raw = ac.filter(target_chembl_id=selected_target)\n","df0 = pd.DataFrame.from_dict(raw)\n","df0"]},{"cell_type":"code","execution_count":null,"id":"c182a802","metadata":{"id":"c182a802"},"outputs":[],"source":["df0.to_csv('PARP1_00_bioactivity_data_raw.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"66abe9f6","metadata":{"id":"66abe9f6"},"outputs":[],"source":["res_IC50 = ac.filter(target_chembl_id=selected_target).filter(standard_type=\"IC50\")"]},{"cell_type":"code","execution_count":null,"id":"814b0e89","metadata":{"id":"814b0e89"},"outputs":[],"source":["df_IC50 = pd.DataFrame.from_dict(res_IC50)"]},{"cell_type":"code","execution_count":null,"id":"5219e17a","metadata":{"id":"5219e17a"},"outputs":[],"source":["df_IC50.to_csv('PARP1_01_bioactivity_IC50_data_raw.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"a58cfc0b","metadata":{"id":"a58cfc0b"},"outputs":[],"source":["#Remove missing data\n","df2_IC50 = df_IC50[df_IC50.standard_value.notna()]\n","df2_IC50 = df2_IC50[df_IC50.canonical_smiles.notna()]"]},{"cell_type":"code","execution_count":null,"id":"a2ecc764","metadata":{"id":"a2ecc764"},"outputs":[],"source":["#Remove duplicate data in canonical_smiles column\n","df2_nr_IC50 = df2_IC50.drop_duplicates(['canonical_smiles'])"]},{"cell_type":"code","execution_count":null,"id":"5654f0c6","metadata":{"id":"5654f0c6"},"outputs":[],"source":["#Selecting 3 column for further analysis\n","selection = ['molecule_chembl_id','canonical_smiles','standard_value']\n","df3_IC50 = df2_nr_IC50[selection]"]},{"cell_type":"code","execution_count":null,"id":"b07aa63d","metadata":{"id":"b07aa63d"},"outputs":[],"source":["df3_IC50.to_csv('PARP1_02_bioactivity_IC50_data_preprocessed.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"342113ea","metadata":{"id":"342113ea"},"outputs":[],"source":["df4_IC50 = pd.read_csv('PARP1_02_bioactivity_IC50_data_preprocessed.csv')"]},{"cell_type":"code","execution_count":null,"id":"77ad9ecd","metadata":{"id":"77ad9ecd"},"outputs":[],"source":["bioactivity_threshold = []\n","for i in df4_IC50.standard_value:\n","  if float(i) >= 10000:\n","    bioactivity_threshold.append(\"inactive\")\n","  elif float(i) <= 1000:\n","    bioactivity_threshold.append(\"active\")\n","  else:\n","    bioactivity_threshold.append(\"intermediate\")\n","    \n","bioactivity_class = pd.Series(bioactivity_threshold, name='class')\n","df5_IC50 = pd.concat([df4_IC50, bioactivity_class], axis=1)"]},{"cell_type":"code","execution_count":null,"id":"19bc083f","metadata":{"id":"19bc083f"},"outputs":[],"source":["df5_IC50.to_csv('PARP1_03_bioactivity_IC50_data_curated.csv', index=False)"]},{"cell_type":"markdown","id":"9029d138","metadata":{"id":"9029d138"},"source":["### 02_Exploratory analysis"]},{"cell_type":"code","execution_count":null,"id":"823908cd","metadata":{"id":"823908cd"},"outputs":[],"source":["#run with python 3.7\n","! conda install -c rdkit rdkit -y\n","import sys\n","sys.path.append('/usr/local/lib/python3.7/site-packages/')"]},{"cell_type":"code","execution_count":null,"id":"efeb3fe7","metadata":{"id":"efeb3fe7"},"outputs":[],"source":["df = pd.read_csv('PARP1_03_bioactivity_IC50_data_curated.csv')"]},{"cell_type":"code","execution_count":null,"id":"8047cf09","metadata":{"id":"8047cf09"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"id":"c0158bb6","metadata":{"id":"c0158bb6"},"outputs":[],"source":["class_ac = df['class'].value_counts()\n","class_ac.columns = ['class','count']\n","class_table = pd.DataFrame(class_ac)\n","class_table"]},{"cell_type":"code","execution_count":null,"id":"3b2f00c2","metadata":{"id":"3b2f00c2"},"outputs":[],"source":["class_table.to_csv('PARP1_bioactivity_profile_IC50.csv')"]},{"cell_type":"code","execution_count":null,"id":"c614c713","metadata":{"id":"c614c713"},"outputs":[],"source":["df_no_smiles = df.drop(columns='canonical_smiles')"]},{"cell_type":"code","execution_count":null,"id":"f8b17af4","metadata":{"id":"f8b17af4"},"outputs":[],"source":["smiles = []\n","\n","for i in df.canonical_smiles.tolist():\n","  cpd = str(i).split('.')\n","  cpd_longest = max(cpd, key = len)\n","  smiles.append(cpd_longest)\n","\n","smiles = pd.Series(smiles, name = 'canonical_smiles')"]},{"cell_type":"code","execution_count":null,"id":"788a0cfc","metadata":{"id":"788a0cfc"},"outputs":[],"source":["df_clean_smiles = pd.concat([df_no_smiles,smiles], axis=1)\n","df_clean_smiles"]},{"cell_type":"code","execution_count":null,"id":"5d32b2dd","metadata":{"id":"5d32b2dd"},"outputs":[],"source":["import numpy as np\n","from rdkit import Chem\n","from rdkit.Chem import Descriptors, Lipinski"]},{"cell_type":"code","execution_count":null,"id":"2ad43e69","metadata":{"id":"2ad43e69"},"outputs":[],"source":["# Inspired by: https://codeocean.com/explore/capsules?query=tag:data-curation\n","\n","def lipinski(smiles, verbose=False):\n","\n","    moldata= []\n","    for elem in smiles:\n","        mol=Chem.MolFromSmiles(elem) \n","        moldata.append(mol)\n","       \n","    baseData= np.arange(1,1)\n","    i=0  \n","    for mol in moldata:        \n","       \n","        desc_MolWt = Descriptors.MolWt(mol)\n","        desc_MolLogP = Descriptors.MolLogP(mol)\n","        desc_NumHDonors = Lipinski.NumHDonors(mol)\n","        desc_NumHAcceptors = Lipinski.NumHAcceptors(mol)\n","           \n","        row = np.array([desc_MolWt,\n","                        desc_MolLogP,\n","                        desc_NumHDonors,\n","                        desc_NumHAcceptors])   \n","    \n","        if(i==0):\n","            baseData=row\n","        else:\n","            baseData=np.vstack([baseData, row])\n","        i=i+1      \n","    \n","    columnNames=[\"MW\",\"LogP\",\"NumHDonors\",\"NumHAcceptors\"]   \n","    descriptors = pd.DataFrame(data=baseData,columns=columnNames)\n","    \n","    return descriptors"]},{"cell_type":"code","execution_count":null,"id":"053b3f1f","metadata":{"id":"053b3f1f"},"outputs":[],"source":["df_lipinski = lipinski(df.canonical_smiles)\n","df_lipinski"]},{"cell_type":"code","execution_count":null,"id":"7a70f04f","metadata":{"id":"7a70f04f"},"outputs":[],"source":["df_combined = pd.concat([df,df_lipinski], axis=1)\n","df_combined"]},{"cell_type":"code","execution_count":null,"id":"5f97738c","metadata":{"id":"5f97738c"},"outputs":[],"source":["import numpy as np\n","\n","def pIC50(input):\n","    pIC50 = []\n","\n","    for i in input['standard_value_norm']:\n","        molar = i*(10**-9) # Converts nM to M\n","        pIC50.append(-np.log10(molar))\n","\n","    input['pIC50'] = pIC50\n","    x = input.drop('standard_value_norm', 1)\n","        \n","    return x"]},{"cell_type":"code","execution_count":null,"id":"04863ca5","metadata":{"id":"04863ca5"},"outputs":[],"source":["df_combined.standard_value.describe()"]},{"cell_type":"code","execution_count":null,"id":"4b95c5b9","metadata":{"id":"4b95c5b9"},"outputs":[],"source":["-np.log10( (10**-9)* 100000000 )"]},{"cell_type":"code","execution_count":null,"id":"2c09a288","metadata":{"id":"2c09a288"},"outputs":[],"source":["-np.log10( (10**-9)* 10000000000 )"]},{"cell_type":"code","execution_count":null,"id":"1548094b","metadata":{"id":"1548094b"},"outputs":[],"source":["def norm_value(input):\n","    norm = []\n","\n","    for i in input['standard_value']:\n","        if i > 100000000:\n","          i = 100000000\n","        norm.append(i)\n","\n","    input['standard_value_norm'] = norm\n","    x = input.drop('standard_value', 1)\n","        \n","    return x"]},{"cell_type":"code","execution_count":null,"id":"cf1bdcc9","metadata":{"id":"cf1bdcc9"},"outputs":[],"source":["df_norm = norm_value(df_combined)\n","df_norm"]},{"cell_type":"code","execution_count":null,"id":"192d210a","metadata":{"id":"192d210a"},"outputs":[],"source":["df_norm.standard_value_norm.describe()"]},{"cell_type":"code","execution_count":null,"id":"b2787fdc","metadata":{"id":"b2787fdc"},"outputs":[],"source":["df_final = pIC50(df_norm)\n","df_final"]},{"cell_type":"code","execution_count":null,"id":"847ee719","metadata":{"id":"847ee719"},"outputs":[],"source":["df_final.pIC50.describe()"]},{"cell_type":"code","execution_count":null,"id":"16d792f1","metadata":{"id":"16d792f1"},"outputs":[],"source":["df_final.to_csv('PARP1_04_bioactivity_data_3class_pIC50.csv')"]},{"cell_type":"code","execution_count":null,"id":"992de72c","metadata":{"id":"992de72c"},"outputs":[],"source":["#Removing the 'intermediate' bioactivity class\n","df_2class = df_final[df_final['class']  != 'intermediate']\n","df_2class"]},{"cell_type":"code","execution_count":null,"id":"5fb7d048","metadata":{"id":"5fb7d048"},"outputs":[],"source":["df_2class.to_csv('PARP1_05_bioactivity_data_2class_pIC50.csv')"]},{"cell_type":"code","execution_count":null,"id":"1bb919c1","metadata":{"id":"1bb919c1"},"outputs":[],"source":["#Statistical\n","mean_MW = df_2class.groupby('class')[\"MW\"].mean()\n","SD_MW = df_2class.groupby('class')[\"MW\"].std()\n","mean_LogP = df_2class.groupby('class')[\"LogP\"].mean()\n","SD_LogP = df_2class.groupby('class')[\"LogP\"].std()\n","mean_NumHDonors = df_2class.groupby('class')[\"NumHDonors\"].mean()\n","SD_NumHDonors = df_2class.groupby('class')[\"NumHDonors\"].std()\n","mean_NumHAcceptors = df_2class.groupby('class')[\"NumHAcceptors\"].mean()\n","SD_NumHAcceptors = df_2class.groupby('class')[\"NumHAcceptors\"].std()"]},{"cell_type":"code","execution_count":null,"id":"1ec84dfa","metadata":{"id":"1ec84dfa"},"outputs":[],"source":["total = [mean_MW,SD_MW,mean_LogP,SD_LogP,mean_NumHDonors,SD_NumHDonors,mean_NumHAcceptors,SD_NumHAcceptors]\n","label=['meanMWac', 'meanMWin','SDMWac', 'SDMWin',\n","     'meanLogPac', 'meanLogPin','SDLogPac','SDLogPin',\n","     'meanNumHDonorsac','meanNumHDonorsin','SDNumHDonorsac','SDNumHDonorsin',\n","    'meanNumHAcceptorsac', 'meanNumHAcceptorsin','SDNumHAcceptorsac','SDNumHAcceptorsin']"]},{"cell_type":"code","execution_count":null,"id":"e4840f61","metadata":{"id":"e4840f61"},"outputs":[],"source":["statistic_Ro5 = pd.concat(total, axis=0)\n","Ro5 = pd.DataFrame(statistic_Ro5, columns=[\"stat\"])\n","Ro5['label']= label\n","Ro5"]},{"cell_type":"code","execution_count":null,"id":"9d598571","metadata":{"id":"9d598571"},"outputs":[],"source":["Ro5.to_csv(\"Ro5_stat.csv\",index=True)"]},{"cell_type":"code","execution_count":null,"id":"e2a137ed","metadata":{"id":"e2a137ed"},"outputs":[],"source":["!pip install seaborn"]},{"cell_type":"code","execution_count":null,"id":"9f6b5bb3","metadata":{"id":"9f6b5bb3"},"outputs":[],"source":["import seaborn as sns\n","sns.set(style='ticks')\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"id":"9e2426e0","metadata":{"id":"9e2426e0"},"outputs":[],"source":["plt.figure(figsize=(7, 7))\n","\n","sns.countplot(x='class', data=df_2class, edgecolor='black')\n","\n","plt.xlabel('bioactivity class', fontsize=14, fontweight='bold')\n","plt.ylabel('Frequency', fontsize=14, fontweight='bold')\n","\n","plt.savefig('plot_bioactivity_class.tiff', bbox_inches='tight', pad_inches=0.1)"]},{"cell_type":"code","execution_count":null,"id":"d793f367","metadata":{"id":"d793f367"},"outputs":[],"source":["plt.figure(figsize=(7, 7))\n","\n","sns.scatterplot(x='MW', y='LogP', data=df_2class, hue='class', size='pIC50', edgecolor='black', alpha=0.2)\n","sns.set_style(\"whitegrid\", {\"ytick.major.size\": 100,\"xtick.major.size\": 2, 'grid.linestyle': 'solid'})\n","\n","plt.xlabel('MW', fontsize=14, fontweight='bold')\n","plt.ylabel('LogP', fontsize=14, fontweight='bold')\n","plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n","\n","plt.savefig('plot_MW_vs_LogP.tiff', bbox_inches='tight', pad_inches=0.1)"]},{"cell_type":"code","execution_count":null,"id":"0f0086e8","metadata":{"id":"0f0086e8"},"outputs":[],"source":["plt.figure(figsize=(5.5, 5.5))\n","\n","sns.boxplot(x = 'class', y = 'pIC50', data = df_2class, medianprops=dict(color=\"black\", alpha=1, linewidth=2))\n","\n","plt.xlabel('Bioactivity class', fontsize=14, fontweight='bold')\n","plt.ylabel('pIC50 value', fontsize=14, fontweight='bold')\n","\n","plt.savefig('plot_IC50.tiff')"]},{"cell_type":"markdown","id":"a81de89d","metadata":{"id":"a81de89d"},"source":["####  Statistical analysis | Mann-Whitney U Test"]},{"cell_type":"code","execution_count":null,"id":"93c1e4b6","metadata":{"id":"93c1e4b6"},"outputs":[],"source":["def mannwhitney(descriptor, verbose=False):\n","  # https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/\n","  from numpy.random import seed\n","  from numpy.random import randn\n","  from scipy.stats import mannwhitneyu\n","\n","# seed the random number generator\n","  seed(1)\n","\n","# actives and inactives\n","  selection = [descriptor, 'class']\n","  df = df_2class[selection]\n","  active = df[df['class'] == 'active']\n","  active = active[descriptor]\n","\n","  selection = [descriptor, 'class']\n","  df = df_2class[selection]\n","  inactive = df[df['class'] == 'inactive']\n","  inactive = inactive[descriptor]\n","\n","# compare samples\n","  stat, p = mannwhitneyu(active, inactive)\n","  #print('Statistics=%.3f, p=%.3f' % (stat, p))\n","\n","# interpret\n","  alpha = 0.05\n","  if p > alpha:\n","    interpretation = 'Same distribution (fail to reject H0)'\n","  else:\n","    interpretation = 'Different distribution (reject H0)'\n","  \n","  results = pd.DataFrame({'Descriptor':descriptor,\n","                          'Statistics':stat,\n","                          'p':p,\n","                          'alpha':alpha,\n","                          'Interpretation':interpretation}, index=[0])\n","  filename = 'mannwhitneyu_' + descriptor + '.csv'\n","  results.to_csv(filename)\n","\n","  return results"]},{"cell_type":"code","execution_count":null,"id":"337f88b9","metadata":{"id":"337f88b9"},"outputs":[],"source":["mannwhitney('pIC50')"]},{"cell_type":"code","execution_count":null,"id":"1778f014","metadata":{"id":"1778f014"},"outputs":[],"source":["pip install statannotations"]},{"cell_type":"code","execution_count":null,"id":"8edbf533","metadata":{"id":"8edbf533"},"outputs":[],"source":["pip install statsmodels"]},{"cell_type":"code","execution_count":null,"id":"162dad08","metadata":{"id":"162dad08"},"outputs":[],"source":["from statannotations.Annotator import Annotator"]},{"cell_type":"markdown","id":"1440f5b2","metadata":{"id":"1440f5b2"},"source":["#### MW"]},{"cell_type":"code","execution_count":null,"id":"9c55bc14","metadata":{"id":"9c55bc14"},"outputs":[],"source":["plt.figure(figsize=(5.5, 5.5))\n","\n","ax = sns.boxplot(x = 'class', y = 'MW', data = df_2class, showmeans = True, meanprops={\"marker\":\"o\",\"markerfacecolor\":\"white\", \n","                       \"markeredgecolor\":\"black\",\"markersize\":\"8\"},\n","                     medianprops=dict(color=\"black\", alpha=1, linewidth=3))\n","ax.axhline(500, ls='--',c = 'black')\n","ax.set(ylim=(100, 850))\n","ax.set(xlabel=None)\n","\n","plt.ylabel('MW', fontsize=14, fontweight='bold')\n","\n","plt.savefig('plot_MW.tiff')"]},{"cell_type":"code","execution_count":null,"id":"23ad1811","metadata":{"id":"23ad1811"},"outputs":[],"source":["mannwhitney('MW')"]},{"cell_type":"markdown","id":"1ce87473","metadata":{"id":"1ce87473"},"source":["#### LogP"]},{"cell_type":"code","execution_count":null,"id":"83e83f0e","metadata":{"id":"83e83f0e"},"outputs":[],"source":["plt.figure(figsize=(5.5, 5.5))\n","\n","ax = sns.boxplot(x = 'class', y = 'LogP', data = df_2class, showmeans = True, meanprops={\"marker\":\"o\",\"markerfacecolor\":\"white\", \n","                       \"markeredgecolor\":\"black\",\"markersize\":\"8\"},\n","                     medianprops=dict(color=\"black\", alpha=1, linewidth=3))\n","ax.axhline(5, ls='--',c = 'black')\n","ax.set(ylim=(-6, 12))\n","ax.set(xlabel=None)\n","\n","plt.ylabel('LogP', fontsize=14, fontweight='bold')\n","\n","plt.savefig('plot_LogP.tiff')"]},{"cell_type":"code","execution_count":null,"id":"4515ba9f","metadata":{"id":"4515ba9f"},"outputs":[],"source":["mannwhitney('LogP')"]},{"cell_type":"markdown","id":"5e9573b1","metadata":{"id":"5e9573b1"},"source":["#### NumHDonor"]},{"cell_type":"code","execution_count":null,"id":"76346793","metadata":{"id":"76346793"},"outputs":[],"source":["plt.figure(figsize=(5.5, 5.5))\n","\n","ax = sns.boxplot(x = 'class', y = 'NumHDonors', data = df_2class, \n","                 showmeans = True, meanprops={\"marker\":\"o\",\"markerfacecolor\":\"white\", \n","                       \"markeredgecolor\":\"black\",\"markersize\":\"8\"},\n","                     medianprops=dict(color=\"black\", alpha=1, linewidth=3))\n","ax.axhline(5, ls='--',c = 'black')\n","ax.set(ylim=(-0.5,10.5))\n","ax.set(xlabel=None)\n","\n","plt.ylabel('NumHDonors', fontsize=14, fontweight='bold')\n","               \n","plt.savefig('plot_NumHDonors.tiff')"]},{"cell_type":"code","execution_count":null,"id":"41f9f4ba","metadata":{"id":"41f9f4ba"},"outputs":[],"source":["mannwhitney('NumHDonors')"]},{"cell_type":"markdown","id":"b43cbbda","metadata":{"id":"b43cbbda"},"source":["#### NumHAcceptors"]},{"cell_type":"code","execution_count":null,"id":"88f8de46","metadata":{"id":"88f8de46"},"outputs":[],"source":["plt.figure(figsize=(5.5, 5.5))\n","\n","ax = sns.boxplot(x = 'class', y = 'NumHAcceptors', data = df_2class, showmeans = True, meanprops={\"marker\":\"o\",\"markerfacecolor\":\"white\", \n","                       \"markeredgecolor\":\"black\",\"markersize\":\"8\"},\n","                     medianprops=dict(color=\"black\", alpha=1, linewidth=3))\n","ax.axhline(10, ls='--',c = 'black')\n","ax.set(ylim=(0, 20))\n","ax.set(xlabel=None)\n","\n","plt.ylabel('NumHAcceptors', fontsize=14, fontweight='bold')\n","\n","plt.savefig('plot_NumHAcceptors.tiff')"]},{"cell_type":"code","execution_count":null,"id":"80179e7a","metadata":{"id":"80179e7a"},"outputs":[],"source":["mannwhitney('NumHAcceptors')"]},{"cell_type":"code","execution_count":null,"id":"8d469507","metadata":{"id":"8d469507"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"id":"2bbaac67","metadata":{"id":"2bbaac67"},"outputs":[],"source":["!zip -r results.zip . -i *.csv *.tiff"]},{"cell_type":"markdown","id":"e3ed4b55","metadata":{"id":"e3ed4b55"},"source":["### 03_Molecular descriptors"]},{"cell_type":"code","execution_count":null,"id":"f13b9a10","metadata":{"id":"f13b9a10"},"outputs":[],"source":["pip install wget"]},{"cell_type":"code","execution_count":null,"id":"b2ed3f45","metadata":{"id":"b2ed3f45"},"outputs":[],"source":["import wget\n","from zipfile import ZipFile\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"4ef22cb2","metadata":{"id":"4ef22cb2"},"outputs":[],"source":["#conda install m2-base"]},{"cell_type":"code","execution_count":null,"id":"9abf0bd7","metadata":{"id":"9abf0bd7"},"outputs":[],"source":["#wget.download('https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/AtomPairs2DFingerprintCount.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/AtomPairs2DFingerprinter.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/EStateFingerprinter.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/ExtendedFingerprinter.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/Fingerprinter.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/GraphOnlyFingerprinter.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/KlekotaRothFingerprintCount.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/KlekotaRothFingerprinter.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/MACCSFingerprinter.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/PubchemFingerprinter.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/SubstructureFingerprintCount.sh')\n","wget.download('https://raw.githubusercontent.com/tlerksuthirat/PaDEL/master/SubstructureFingerprinter.sh')"]},{"cell_type":"code","execution_count":null,"id":"1d4bb534","metadata":{"id":"1d4bb534"},"outputs":[],"source":["zipObj = ZipFile(\"padel.zip\", \"r\")\n","zipObj.extractall()\n","zipObj.close()"]},{"cell_type":"code","execution_count":null,"id":"c0ba6f1b","metadata":{"id":"c0ba6f1b"},"outputs":[],"source":["df = pd.read_csv('PARP1_05_bioactivity_data_2class_pIC50.csv')\n","df"]},{"cell_type":"code","execution_count":null,"id":"53d82e70","metadata":{"id":"53d82e70"},"outputs":[],"source":["df = df.sort_values(by='class',ascending=True)"]},{"cell_type":"code","execution_count":null,"id":"1168d5a5","metadata":{"id":"1168d5a5"},"outputs":[],"source":["df.to_csv('PARP1_05_bioactivity_data_2class_pIC50_sort_class.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"ffe0efcb","metadata":{"id":"ffe0efcb"},"outputs":[],"source":["selection = ['canonical_smiles','molecule_chembl_id']\n","df_selection = df[selection]\n","df_selection.to_csv('molecule_pos_neg_sort.smi', sep='\\t', index=False, header=False)"]},{"cell_type":"code","execution_count":null,"id":"ea95b8e7","metadata":{"id":"ea95b8e7"},"outputs":[],"source":["df_selection"]},{"cell_type":"code","execution_count":null,"id":"32f627c7","metadata":{"id":"32f627c7"},"outputs":[],"source":["!cat molecule_pos_neg_sort.smi | head -5"]},{"cell_type":"code","execution_count":null,"id":"e5e85533","metadata":{"id":"e5e85533"},"outputs":[],"source":["!cat molecule_pos_neg_sort.smi | wc -l"]},{"cell_type":"code","execution_count":null,"id":"47d831ab","metadata":{"id":"47d831ab"},"outputs":[],"source":["!cat AtomPairs2DFingerprintCount.sh\n","!bash AtomPairs2DFingerprintCount.sh"]},{"cell_type":"code","execution_count":null,"id":"04449348","metadata":{"id":"04449348"},"outputs":[],"source":["!cat AtomPairs2DFingerprinter.sh\n","!bash AtomPairs2DFingerprinter.sh"]},{"cell_type":"code","execution_count":null,"id":"9371b50a","metadata":{"id":"9371b50a"},"outputs":[],"source":["!cat EStateFingerprinter.sh\n","!bash EStateFingerprinter.sh"]},{"cell_type":"code","execution_count":null,"id":"9b72e665","metadata":{"id":"9b72e665"},"outputs":[],"source":["!cat ExtendedFingerprinter.sh\n","!bash ExtendedFingerprinter.sh"]},{"cell_type":"code","execution_count":null,"id":"ed26dc79","metadata":{"id":"ed26dc79"},"outputs":[],"source":["!cat Fingerprinter.sh\n","!bash Fingerprinter.sh"]},{"cell_type":"code","execution_count":null,"id":"916619c6","metadata":{"id":"916619c6"},"outputs":[],"source":["!cat GraphOnlyFingerprinter.sh\n","!bash GraphOnlyFingerprinter.sh"]},{"cell_type":"code","execution_count":null,"id":"39f37a07","metadata":{"id":"39f37a07"},"outputs":[],"source":["!cat KlekotaRothFingerprintCount.sh\n","!bash KlekotaRothFingerprintCount.sh"]},{"cell_type":"code","execution_count":null,"id":"0047f2a8","metadata":{"id":"0047f2a8"},"outputs":[],"source":["!cat KlekotaRothFingerprinter.sh\n","!bash KlekotaRothFingerprinter.sh"]},{"cell_type":"code","execution_count":null,"id":"cdf8230b","metadata":{"id":"cdf8230b"},"outputs":[],"source":["!cat MACCSFingerprinter.sh\n","!bash MACCSFingerprinter.sh"]},{"cell_type":"code","execution_count":null,"id":"bee3f81c","metadata":{"id":"bee3f81c"},"outputs":[],"source":["!cat PubchemFingerprinter.sh\n","!bash PubchemFingerprinter.sh"]},{"cell_type":"code","execution_count":null,"id":"75fd9ca5","metadata":{"id":"75fd9ca5"},"outputs":[],"source":["!cat SubstructureFingerprintCount.sh\n","!bash SubstructureFingerprintCount.sh"]},{"cell_type":"code","execution_count":null,"id":"55735887","metadata":{"id":"55735887"},"outputs":[],"source":["!cat SubstructureFingerprinter.sh\n","!bash SubstructureFingerprinter.sh"]},{"cell_type":"markdown","id":"04aafb99","metadata":{"id":"04aafb99"},"source":["### Read in fingerprints"]},{"cell_type":"code","execution_count":null,"id":"8ab41ff7","metadata":{"id":"8ab41ff7"},"outputs":[],"source":["import os\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"0d7f3f23","metadata":{"id":"0d7f3f23"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github')\n","df_x_AFC = pd.read_csv('descriptors_output_AtomPairs2DFingerprintCount.csv')\n","df_x_AF = pd.read_csv('descriptors_output_AtomPairs2DFingerprinter.csv')\n","df_x_ESF = pd.read_csv('descriptors_output_EStateFingerprinter.csv')\n","df_x_EXF = pd.read_csv('descriptors_output_ExtendedFingerprinter.csv')\n","df_x_F = pd.read_csv('descriptors_output_Fingerprinter.csv')\n","df_x_GF = pd.read_csv('descriptors_output_GraphOnlyFingerprinter.csv')\n","df_x_KRFC = pd.read_csv('descriptors_output_KlekotaRothFingerprintCount.csv')\n","df_x_KRF = pd.read_csv('descriptors_output_KlekotaRothFingerprinter.csv')\n","df_x_MF = pd.read_csv('descriptors_output_MACCSFingerprinter.csv')\n","df_x_PF = pd.read_csv('descriptors_output_PubchemFingerprinter.csv')\n","df_x_SFC = pd.read_csv('descriptors_output_SubstructureFingerprintCount.csv')\n","df_x_SF = pd.read_csv('descriptors_output_SubstructureFingerprinter.csv')"]},{"cell_type":"code","execution_count":null,"id":"37f5712f","metadata":{"id":"37f5712f"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('PARP1_05_bioactivity_data_2class_pIC50_sort_class.csv')\n","df =  df.iloc[:, 1:]\n","df"]},{"cell_type":"code","execution_count":null,"id":"b8c0d6af","metadata":{"id":"b8c0d6af"},"outputs":[],"source":["os.mkdir('fingerprint')"]},{"cell_type":"code","execution_count":null,"id":"3d414f66","metadata":{"id":"3d414f66"},"outputs":[],"source":["os.chdir('fingerprint')"]},{"cell_type":"code","execution_count":null,"id":"b86ab235","metadata":{"id":"b86ab235"},"outputs":[],"source":["df_x_AFC.to_csv('AtomPairs2DCount.csv', index=False)\n","df_x_AF.to_csv('AtomPairs2D.csv', index=False)\n","df_x_ESF.to_csv('EState.csv', index=False)\n","df_x_EXF.to_csv('CDKextended.csv', index=False)\n","df_x_F.to_csv('CDK.csv', index=False)\n","df_x_GF.to_csv('CDKgraphonly.csv', index=False)\n","df_x_KRFC.to_csv('KlekotaRothCount.csv', index=False)\n","df_x_KRF.to_csv('KlekotaRoth.csv', index=False)\n","df_x_MF.to_csv('MACCS.csv', index=False)\n","df_x_PF.to_csv('PubChem.csv', index=False)\n","df_x_SFC.to_csv('SubstructureCount.csv', index=False)\n","df_x_SF.to_csv('Substructure.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"d0a27b51","metadata":{"id":"d0a27b51"},"outputs":[],"source":["# Create variables to house fingerprint descriptors as DataFrames\n","os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github')\n","\n","FP_list = ['AtomPairs2DCount',\n"," 'AtomPairs2D',\n"," 'EState',\n"," 'CDKextended',\n"," 'CDK',\n"," 'CDKgraphonly',\n"," 'KlekotaRothCount',\n"," 'KlekotaRoth',\n"," 'MACCS',\n"," 'PubChem',\n"," 'SubstructureCount',\n"," 'Substructure']\n","\n","for i in FP_list:\n","  fp = f'fingerprint/{i}.csv'\n","  descriptors = pd.read_csv(fp, index_col=False)\n","  exec(i + '= descriptors')"]},{"cell_type":"markdown","id":"9f1eba55","metadata":{"id":"9f1eba55"},"source":["### 04_Model construction"]},{"cell_type":"code","execution_count":null,"id":"50d12c29","metadata":{"id":"50d12c29"},"outputs":[],"source":["pip install xgboost"]},{"cell_type":"code","execution_count":null,"id":"c4f428d8","metadata":{"id":"c4f428d8"},"outputs":[],"source":["pip install lightgbm"]},{"cell_type":"code","execution_count":null,"id":"9f0379d1","metadata":{"id":"9f0379d1"},"outputs":[],"source":["pip install scikit-learn"]},{"cell_type":"code","execution_count":null,"id":"ed7a1261","metadata":{"id":"ed7a1261"},"outputs":[],"source":["# Data processing\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.model_selection import train_test_split\n","\n","# Import Classifiers\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from xgboost.sklearn import XGBClassifier\n","from lightgbm.sklearn import LGBMClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","\n","# Cross-validation\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import cross_val_score\n","\n","# Model performance metric\n","from sklearn.metrics import make_scorer\n","from sklearn.metrics import accuracy_score, recall_score, matthews_corrcoef"]},{"cell_type":"code","execution_count":null,"id":"c72d8a36","metadata":{"id":"c72d8a36"},"outputs":[],"source":["classifier_list = {'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42),\n","                  'GradientBoostingClassifier': GradientBoostingClassifier(random_state=42),\n","                  'KNeighborsClassifier': KNeighborsClassifier(),\n","                  'MLPClassifier': MLPClassifier(random_state=42),\n","                  'RandomForestClassifier': RandomForestClassifier(random_state=42),\n","                  'SVC': SVC(kernel='rbf', random_state=42),#remove class_weight\n","                  'XGBClassifier': XGBClassifier(random_state=42),\n","                  'LGBMClassifier': LGBMClassifier(random_state=42),\n","                  'ExtraTreesClassifier': ExtraTreesClassifier(random_state=42),\n","                  'GaussianProcessClassifier': GaussianProcessClassifier(random_state=42),\n","                  'GaussianNB': GaussianNB(),\n","                  'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis()}"]},{"cell_type":"code","execution_count":null,"id":"539755fd","metadata":{"id":"539755fd"},"outputs":[],"source":["! pip install -U imbalanced-learn"]},{"cell_type":"code","execution_count":null,"id":"5765b386","metadata":{"id":"5765b386"},"outputs":[],"source":["# Class balancing\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import RandomOverSampler\n","\n","import pickle\n","\n","def remove_low_variance(input_data, threshold=0.1):\n","    selection = VarianceThreshold(threshold)\n","    selection.fit(input_data)\n","    return input_data[input_data.columns[selection.get_support(indices=True)]]\n","\n","def model_building(features_df, bioactivity_class, classifier, balancing):\n","  \n","  # Preparing X and y\n","  df = eval(features_df)\n","  X = df.drop('Name', axis=1)\n","  y = bioactivity_class\n","  y = pd.Series(y)\n","\n","  def target_encode(val):\n","    target_mapper = {'inactive':0, 'active':1}\n","    return target_mapper[val]\n","\n","  y = y.apply(target_encode)\n","\n","  # Remove low variance features\n","  X2 = remove_low_variance(X, threshold=0.01)\n","  X2.to_csv(f'{balancing}_{features_df}_removed_low_variance_0.1.csv', index=False)\n","  \n","  # Data splitting\n","  X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.2, random_state=42)\n","  X_train.to_csv(f'{balancing}_{features_df}_X_train.csv', index=False)\n","  y_train.to_csv(f'{balancing}_{features_df}_y_train.csv', index=False)\n","  X_test.to_csv(f'{balancing}_{features_df}_X_test.csv', index=False)\n","  y_test.to_csv(f'{balancing}_{features_df}_y_test.csv', index=False)\n","\n","  # Oversampling\n","  if balancing == 'oversampling':\n","    ros = RandomOverSampler(sampling_strategy=\"not majority\") # String\n","    X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n","    X_train = X_train_ros\n","    y_train = y_train_ros\n","  if balancing == 'undersampling':\n","    rus = RandomUnderSampler(sampling_strategy=1) # Numerical value\n","    X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n","    X_train = X_train_rus\n","    y_train = y_train_rus\n","  else:\n","    pass\n","\n","  # Model building\n","  model = classifier_list[classifier]\n","  model.fit(X_train, y_train)\n","  # Saving the model\n","  pickle.dump(model, open(f'{balancing}_{features_df}_{classifier}.pkl', 'wb'))\n","\n","  # Apply model to make prediction\n","  y_train_pred = model.predict(X_train)\n","  y_test_pred = model.predict(X_test)\n","  \n","  # Building a CV model\n","  model_cv = classifier_list[classifier]\n","  #cv = cross_validate(model_cv, X_train, y_train, cv=5, scoring=make_scorer(matthews_corrcoef))\n","  cv_scoring = {'Ac': 'accuracy', 'Sn': make_scorer(recall_score), 'Sp': make_scorer(recall_score, pos_label=0), 'MCC': make_scorer(matthews_corrcoef)}\n","  cv = cross_validate(model_cv, X_train, y_train, cv=5, scoring=cv_scoring)\n","\n","  # Calculating model performance\n","  ac_train = accuracy_score(y_train, y_train_pred)\n","  ac_test = accuracy_score(y_test, y_test_pred)\n","  ac_cv = cv['test_Ac'].mean()\n","\n","  sn_train = recall_score(y_train, y_train_pred)\n","  sn_test = recall_score(y_test, y_test_pred)\n","  sn_cv = cv['test_Sn'].mean()\n","\n","  sp_train = recall_score(y_train, y_train_pred, pos_label=0)\n","  sp_test = recall_score(y_test, y_test_pred, pos_label=0)\n","  sp_cv = cv['test_Sp'].mean()\n","\n","  mcc_train = matthews_corrcoef(y_train, y_train_pred)\n","  mcc_test = matthews_corrcoef(y_test, y_test_pred)\n","  mcc_cv = cv['test_MCC'].mean()\n","  \n","  # Preparing performance summary table\n","  model_name = pd.Series([classifier], name='Algorithm')\n","\n","  ac_train_series = pd.Series(ac_train, name='Ac_train')\n","  ac_test_series = pd.Series(ac_test, name='Ac_test')\n","  ac_cv_series = pd.Series(ac_cv, name='Ac_cv')\n","\n","  sn_train_series = pd.Series(sn_train, name='Sn_train')\n","  sn_test_series = pd.Series(sn_test, name='Sn_test')\n","  sn_cv_series = pd.Series(sn_cv, name='Sn_cv')\n","\n","  sp_train_series = pd.Series(sp_train, name='Sp_train')\n","  sp_test_series = pd.Series(sp_test, name='Sp_test')\n","  sp_cv_series = pd.Series(sp_cv, name='Sp_cv')\n","\n","  mcc_train_series = pd.Series(mcc_train, name='MCC_train')\n","  mcc_cv_series = pd.Series(mcc_cv, name='MCC_cv')\n","  mcc_test_series = pd.Series(mcc_test, name='MCC_test')\n","\n","#change the code -- recheck\n","  performance_metrics = pd.concat([model_name,\n","                                   ac_train_series, sn_train_series, sp_train_series, mcc_train_series,\n","                                   ac_cv_series, sn_cv_series, sp_cv_series,  mcc_cv_series,\n","                                   ac_test_series, sn_test_series, sp_test_series, mcc_test_series], axis=1)                           \n","  performance_metrics['MCC_train_cv'] = abs(performance_metrics['MCC_train'] - performance_metrics['MCC_cv'])\n","  performance_metrics['MCC_train_test'] = abs(performance_metrics['MCC_train'] - performance_metrics['MCC_test'])\n","\n","  return performance_metrics"]},{"cell_type":"code","execution_count":null,"id":"dcbe20a6","metadata":{"id":"dcbe20a6"},"outputs":[],"source":["# Iterating through both the Classifier and Fingerprint lists\n","df_list = []\n","\n","for i in classifier_list:\n","  for j in FP_list:\n","    print(j, i)\n","    classifier = model_building(j, df['class'], i, 'normal')\n","    classifier['Fingerprint'] = j\n","    # Reorder last column to be first column\n","    cols = classifier.columns.tolist()\n","    cols = cols[-1:] + cols[:-1] \n","    classifier = classifier[cols]\n","    # Append DataFrame to list\n","    df_list.append(classifier)\n","\n","# Combine DataFrame from list\n","df_final_normal = pd.concat(df_list)\n","df_final_normal.sort_values(by=['Fingerprint'], inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"e12f6d41","metadata":{"id":"e12f6d41"},"outputs":[],"source":["# Iterating through both the Classifier and Fingerprint lists\n","df_list = []\n","\n","for i in classifier_list:\n","  for j in FP_list:\n","    print(j, i)\n","    classifier = model_building(j, df['class'], i, 'oversampling')\n","    classifier['Fingerprint'] = j\n","    # Reorder last column to be first column\n","    cols = classifier.columns.tolist()\n","    cols = cols[-1:] + cols[:-1] \n","    classifier = classifier[cols]\n","    # Append DataFrame to list\n","    df_list.append(classifier)\n","\n","# Combine DataFrame from list\n","df_final_oversampling = pd.concat(df_list)\n","df_final_oversampling.sort_values(by=['Fingerprint'], inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"694645fe","metadata":{"id":"694645fe"},"outputs":[],"source":["# Iterating through both the Classifier and Fingerprint lists\n","df_list = []\n","\n","for i in classifier_list:\n","  for j in FP_list:\n","    print(j, i)\n","    classifier = model_building(j, df['class'], i, 'undersampling')\n","    classifier['Fingerprint'] = j\n","    # Reorder last column to be first column\n","    cols = classifier.columns.tolist()\n","    cols = cols[-1:] + cols[:-1] \n","    classifier = classifier[cols]\n","    # Append DataFrame to list\n","    df_list.append(classifier)\n","\n","# Combine DataFrame from list\n","df_final_undersampling = pd.concat(df_list)\n","df_final_undersampling.sort_values(by=['Fingerprint'], inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"059825c2","metadata":{"id":"059825c2"},"outputs":[],"source":["#imbalanced data\n","df_final_normal.to_csv('normal_results.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"d23f8e52","metadata":{"id":"d23f8e52"},"outputs":[],"source":["df_final_oversampling.to_csv('oversampling_results.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"229381ae","metadata":{"id":"229381ae"},"outputs":[],"source":["df_final_undersampling.to_csv('undersampling_results.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"17f0fc35","metadata":{"id":"17f0fc35"},"outputs":[],"source":["! zip PARP1_normal_models_pkl.zip normal*.pkl\n","! zip PARP1_normal_lowvarianceremoved_datasplit.zip normal*.csv\n","! zip PARP1_oversampling_models_pkl.zip oversampling*.pkl\n","! zip PARP1_oversampling_lowvarianceremoved_datasplit.zip oversampling*.csv\n","! zip PARP1_undersampling_models_pkl.zip undersampling*.pkl\n","! zip PARP1_undersampling_lowvarianceremoved_datasplit.zip undersampling*.csv"]},{"cell_type":"code","execution_count":null,"id":"ccd77ae9","metadata":{"id":"ccd77ae9"},"outputs":[],"source":["! mkdir ZIP\n","! mv *.zip ZIP"]},{"cell_type":"code","execution_count":null,"id":"a66be9ef","metadata":{"id":"a66be9ef"},"outputs":[],"source":["! mkdir results\n","! mv *results.csv results"]},{"cell_type":"code","execution_count":null,"id":"29b2db2e","metadata":{"id":"29b2db2e"},"outputs":[],"source":["! rm normal*.pkl normal*.csv oversampling*.pkl oversampling*.csv undersampling*.pkl undersampling*.csv"]},{"cell_type":"markdown","id":"3feba0a8","metadata":{"id":"3feba0a8"},"source":["### 05_Post-Model Analysis\n","#### restart kernel to clear previous outputs"]},{"cell_type":"code","execution_count":null,"id":"5b6f41a8","metadata":{"id":"5b6f41a8"},"outputs":[],"source":["import os\n","os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')"]},{"cell_type":"code","execution_count":null,"id":"0b8e2fee","metadata":{"id":"0b8e2fee"},"outputs":[],"source":["from zipfile import ZipFile\n","file_name = \"PARP1_normal_lowvarianceremoved_datasplit.zip\"\n","\n","# opening the zip file in READ mode\n","with ZipFile(file_name, 'r') as zip:\n","    # printing all the contents of the zip file\n","    zip.printdir()\n","    \n","    # extracting specific file\n","    print('Extracting all the files now...')\n","    zip.extract('normal_results.csv')\n","    print('Done!')"]},{"cell_type":"code","execution_count":null,"id":"cee8bcbe","metadata":{"id":"cee8bcbe"},"outputs":[],"source":["from zipfile import ZipFile\n","file_name = \"PARP1_oversampling_lowvarianceremoved_datasplit.zip\"\n","\n","# opening the zip file in READ mode\n","with ZipFile(file_name, 'r') as zip:\n","    # printing all the contents of the zip file\n","    zip.printdir()\n","    \n","    # extracting specific file\n","    print('Extracting all the files now...')\n","    zip.extract('oversampling_results.csv')\n","    print('Done!')"]},{"cell_type":"code","execution_count":null,"id":"ab343e66","metadata":{"id":"ab343e66"},"outputs":[],"source":["from zipfile import ZipFile\n","file_name = \"PARP1_undersampling_lowvarianceremoved_datasplit.zip\"\n","\n","# opening the zip file in READ mode\n","with ZipFile(file_name, 'r') as zip:\n","    # printing all the contents of the zip file\n","    zip.printdir()\n","    \n","    # extracting specific file\n","    print('Extracting all the files now...')\n","    zip.extract('undersampling_results.csv')\n","    print('Done!')"]},{"cell_type":"code","execution_count":null,"id":"d1a7a830","metadata":{"id":"d1a7a830"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv('normal_results.csv')\n","pd.set_option('display.float_format', lambda x: '%.3f' % x)\n","df2 = df.copy()\n","df2"]},{"cell_type":"code","execution_count":null,"id":"10778599","metadata":{"id":"10778599"},"outputs":[],"source":["# Custom function for making Heatmap\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","\n","def make_heatmap(score):\n","  # Shaping the data\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  # Making the Heatmap\n","  fig, ax = plt.subplots()\n","  im = ax.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","  #im = ax.imshow(z, cmap='cool')\n","\n","  # Show all ticks\n","  ax.set_xticks(np.arange(len(x)))\n","  ax.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax.set_xticklabels(x)\n","  ax.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","  # Add colorbar\n","  divider = make_axes_locatable(ax)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im, cax=cax)\n","\n","  fig.set_size_inches(9, 9)\n","  fig.tight_layout()\n","  #plt.savefig(f'{score}.pdf')\n","  plt.savefig(f'{score}.tiff')"]},{"cell_type":"code","execution_count":null,"id":"db68ea56","metadata":{"id":"db68ea56"},"outputs":[],"source":["os.mkdir('normal_results')"]},{"cell_type":"markdown","id":"386ea7a7","metadata":{"id":"386ea7a7"},"source":["#### MCC for Training set"]},{"cell_type":"code","execution_count":null,"id":"a26680b5","metadata":{"id":"a26680b5"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\normal_results')\n","make_heatmap('MCC_train')"]},{"cell_type":"markdown","id":"a4b31b01","metadata":{"id":"a4b31b01"},"source":["#### MCC for test set"]},{"cell_type":"code","execution_count":null,"id":"53aa406f","metadata":{"id":"53aa406f"},"outputs":[],"source":["make_heatmap('MCC_test')"]},{"cell_type":"markdown","id":"206e6a9b","metadata":{"id":"206e6a9b"},"source":["#### MCC for CV set"]},{"cell_type":"code","execution_count":null,"id":"9d012563","metadata":{"id":"9d012563"},"outputs":[],"source":["make_heatmap('MCC_cv')"]},{"cell_type":"code","execution_count":null,"id":"6b4c4458","metadata":{"id":"6b4c4458"},"outputs":[],"source":["# Custom function for making Heatmap\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","\n","def make_heatmap_panel_plot():\n","  # Shaping the data\n","\n","  # Making the Heatmap\n","  fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n","  #im = ax.imshow(z, cmap='cool')\n","\n","# ax1\n","  # Data\n","  score1 = 'MCC_train'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score1]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score1]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im1 = ax1.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","  \n","  #add color bar\n","  divider = make_axes_locatable(ax1)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im1, cax=cax)\n","\n","  # Show all ticks\n","  ax1.set_xticks(np.arange(len(x)))\n","  ax1.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax1.set_xticklabels(x)\n","  ax1.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax1.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","# ax2\n","  # Data\n","  score2 = 'MCC_cv'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score2]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score2]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im2 = ax2.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","    \n","  #add color bar\n","  divider = make_axes_locatable(ax2)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im2, cax=cax)\n","\n","  # Show all ticks\n","  ax2.set_xticks(np.arange(len(x)))\n","  ax2.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax2.set_xticklabels(x)\n","  ax2.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax2.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax2.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","# ax3\n","  # Data\n","  score3 = 'MCC_test'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score3]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score3]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im3 = ax3.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","\n","  #add color bar\n","  divider = make_axes_locatable(ax3)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im3, cax=cax)\n","\n","  # Show all ticks\n","  ax3.set_xticks(np.arange(len(x)))\n","  ax3.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax3.set_xticklabels(x)\n","  ax3.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax3.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax3.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","\n","  # Y tick labels\n","  ax2.yaxis.set_ticklabels([])\n","  ax3.yaxis.set_ticklabels([])\n","\n","  # Sub-plot title\n","  ax1.set_title('Training set', fontsize=14, fontweight='bold', pad=15) # Training set\n","  ax2.set_title('CV set', fontsize=14, fontweight='bold', pad=15) # CV set\n","  ax3.set_title('Test set', fontsize=14, fontweight='bold', pad=15) # Test set\n","\n","  # Axes labels\n","  ax1.set_ylabel('Fingerprints', fontweight='bold', fontsize=14, labelpad=15)\n","  ax2.set_xlabel('MCC', fontweight='bold', fontsize=14, labelpad=15)\n","     \n","  fig.set_size_inches(18, 10.5)\n","  fig.tight_layout()\n","  #plt.savefig('Fig_Heatmap_Model_Performance.pdf')\n","  plt.savefig('Fig_Heatmap_Model_Performance.tiff')\n","\n","make_heatmap_panel_plot()"]},{"cell_type":"markdown","id":"497e63fd","metadata":{"id":"497e63fd"},"source":["#### MCC of Training minus MCC of CV set"]},{"cell_type":"code","execution_count":null,"id":"d8a5612c","metadata":{"id":"d8a5612c"},"outputs":[],"source":["make_heatmap('MCC_train_cv')"]},{"cell_type":"markdown","id":"6e0acd50","metadata":{"id":"6e0acd50"},"source":["#### MCC of Training minus MCC of Test set"]},{"cell_type":"code","execution_count":null,"id":"2d24e350","metadata":{"id":"2d24e350"},"outputs":[],"source":["make_heatmap('MCC_train_test')"]},{"cell_type":"markdown","id":"e0fee62d","metadata":{"id":"e0fee62d"},"source":["#### Oversampling_results"]},{"cell_type":"code","execution_count":null,"id":"c21139d1","metadata":{"id":"c21139d1"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')\n","df = pd.read_csv('oversampling_results.csv')\n","pd.set_option('display.float_format', lambda x: '%.3f' % x)\n","df2 = df.copy()\n","df2"]},{"cell_type":"code","execution_count":null,"id":"7fea681d","metadata":{"id":"7fea681d"},"outputs":[],"source":["os.mkdir('oversampling_results')"]},{"cell_type":"code","execution_count":null,"id":"3b86d6b2","metadata":{"id":"3b86d6b2"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\oversampling_results')\n","make_heatmap('MCC_train')"]},{"cell_type":"code","execution_count":null,"id":"b7c02861","metadata":{"id":"b7c02861"},"outputs":[],"source":["make_heatmap('MCC_test')"]},{"cell_type":"code","execution_count":null,"id":"01dbb171","metadata":{"id":"01dbb171"},"outputs":[],"source":["make_heatmap('MCC_cv')"]},{"cell_type":"code","execution_count":null,"id":"db29c510","metadata":{"id":"db29c510"},"outputs":[],"source":["# Custom function for making Heatmap\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","\n","def make_heatmap_panel_plot():\n","  # Shaping the data\n","\n","  # Making the Heatmap\n","  fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n","  #im = ax.imshow(z, cmap='cool')\n","\n","# ax1\n","  # Data\n","  score1 = 'MCC_train'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score1]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score1]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im1 = ax1.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","  \n","  #add color bar\n","  divider = make_axes_locatable(ax1)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im1, cax=cax)\n","\n","  # Show all ticks\n","  ax1.set_xticks(np.arange(len(x)))\n","  ax1.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax1.set_xticklabels(x)\n","  ax1.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax1.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","# ax2\n","  # Data\n","  score2 = 'MCC_cv'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score2]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score2]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im2 = ax2.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","    \n","  #add color bar\n","  divider = make_axes_locatable(ax2)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im2, cax=cax)\n","\n","  # Show all ticks\n","  ax2.set_xticks(np.arange(len(x)))\n","  ax2.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax2.set_xticklabels(x)\n","  ax2.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax2.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax2.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","# ax3\n","  # Data\n","  score3 = 'MCC_test'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score3]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score3]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im3 = ax3.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","\n","  #add color bar\n","  divider = make_axes_locatable(ax3)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im3, cax=cax)\n","\n","  # Show all ticks\n","  ax3.set_xticks(np.arange(len(x)))\n","  ax3.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax3.set_xticklabels(x)\n","  ax3.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax3.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax3.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","\n","  # Y tick labels\n","  ax2.yaxis.set_ticklabels([])\n","  ax3.yaxis.set_ticklabels([])\n","\n","  # Sub-plot title\n","  ax1.set_title('Training set', fontsize=14, fontweight='bold', pad=15) # Training set\n","  ax2.set_title('CV set', fontsize=14, fontweight='bold', pad=15) # CV set\n","  ax3.set_title('Test set', fontsize=14, fontweight='bold', pad=15) # Test set\n","\n","  # Axes labels\n","  ax1.set_ylabel('Fingerprints', fontweight='bold', fontsize=14, labelpad=15)\n","  ax2.set_xlabel('MCC', fontweight='bold', fontsize=14, labelpad=15)\n","     \n","  fig.set_size_inches(18, 10.5)\n","  fig.tight_layout()\n","  #plt.savefig('Fig_Heatmap_Model_Performance.pdf')\n","  plt.savefig('Fig_Heatmap_Model_Performance.tiff')\n","\n","make_heatmap_panel_plot()"]},{"cell_type":"code","execution_count":null,"id":"bd8185fd","metadata":{"id":"bd8185fd"},"outputs":[],"source":["make_heatmap('MCC_train_cv')"]},{"cell_type":"code","execution_count":null,"id":"9bb0acd4","metadata":{"id":"9bb0acd4"},"outputs":[],"source":["make_heatmap('MCC_train_test')"]},{"cell_type":"markdown","id":"d2e355b6","metadata":{"id":"d2e355b6"},"source":["#### Undersampling_results"]},{"cell_type":"code","execution_count":null,"id":"2ba54953","metadata":{"id":"2ba54953"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')\n","df = pd.read_csv('undersampling_results.csv')\n","pd.set_option('display.float_format', lambda x: '%.3f' % x)\n","df2 = df.copy()\n","df2"]},{"cell_type":"code","execution_count":null,"id":"03a3d297","metadata":{"id":"03a3d297"},"outputs":[],"source":["os.mkdir('undersampling_results')"]},{"cell_type":"code","execution_count":null,"id":"52daeb62","metadata":{"id":"52daeb62"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\undersampling_results')\n","make_heatmap('MCC_train')"]},{"cell_type":"code","execution_count":null,"id":"ddd3ca8b","metadata":{"id":"ddd3ca8b"},"outputs":[],"source":["make_heatmap('MCC_test')"]},{"cell_type":"code","execution_count":null,"id":"763514bb","metadata":{"id":"763514bb"},"outputs":[],"source":["make_heatmap('MCC_cv')"]},{"cell_type":"code","execution_count":null,"id":"86e3b4b9","metadata":{"id":"86e3b4b9"},"outputs":[],"source":["# Custom function for making Heatmap\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","\n","def make_heatmap_panel_plot():\n","  # Shaping the data\n","\n","  # Making the Heatmap\n","  fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n","  #im = ax.imshow(z, cmap='cool')\n","\n","# ax1\n","  # Data\n","  score1 = 'MCC_train'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score1]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score1]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im1 = ax1.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","  \n","  #add color bar\n","  divider = make_axes_locatable(ax1)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im1, cax=cax)\n","\n","  # Show all ticks\n","  ax1.set_xticks(np.arange(len(x)))\n","  ax1.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax1.set_xticklabels(x)\n","  ax1.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax1.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","# ax2\n","  # Data\n","  score2 = 'MCC_cv'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score2]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score2]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im2 = ax2.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","    \n","  #add color bar\n","  divider = make_axes_locatable(ax2)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im2, cax=cax)\n","\n","  # Show all ticks\n","  ax2.set_xticks(np.arange(len(x)))\n","  ax2.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax2.set_xticklabels(x)\n","  ax2.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax2.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax2.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","# ax3\n","  # Data\n","  score3 = 'MCC_test'\n","  grid_results = pd.concat([df2.Fingerprint, df2.Algorithm, df2[score3]], axis=1)\n","  grid_contour = grid_results.groupby(['Fingerprint','Algorithm']).mean()\n","  grid_reset = grid_contour.reset_index()\n","  grid_reset.columns = ['Fingerprint', 'Algorithm', score3]\n","  grid_pivot = grid_reset.pivot('Fingerprint', 'Algorithm')\n","  x = grid_pivot.columns.levels[1].values\n","  y = grid_pivot.index.values\n","  z = np.round(grid_pivot.values, 2)\n","\n","  im3 = ax3.imshow(z, cmap='RdBu', vmin=0, vmax=1)\n","\n","  #add color bar\n","  divider = make_axes_locatable(ax3)\n","  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n","  plt.colorbar(im3, cax=cax)\n","\n","  # Show all ticks\n","  ax3.set_xticks(np.arange(len(x)))\n","  ax3.set_yticks(np.arange(len(y)))\n","  # Label all ticks with list entries\n","  ax3.set_xticklabels(x)\n","  ax3.set_yticklabels(y)\n","\n","  # Rotate the tick labels and set their alignment.\n","  plt.setp(ax3.get_xticklabels(), rotation=90, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","\n","  # Loop over data dimensions and create text annotations.\n","  for i in range(len(y)):\n","      for j in range(len(x)):\n","          text = ax3.text(j, i, z[i, j],\n","                        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\")\n","\n","\n","  # Y tick labels\n","  ax2.yaxis.set_ticklabels([])\n","  ax3.yaxis.set_ticklabels([])\n","\n","  # Sub-plot title\n","  ax1.set_title('Training set', fontsize=14, fontweight='bold', pad=15) # Training set\n","  ax2.set_title('CV set', fontsize=14, fontweight='bold', pad=15) # CV set\n","  ax3.set_title('Test set', fontsize=14, fontweight='bold', pad=15) # Test set\n","\n","  # Axes labels\n","  ax1.set_ylabel('Fingerprints', fontweight='bold', fontsize=14, labelpad=15)\n","  ax2.set_xlabel('MCC', fontweight='bold', fontsize=14, labelpad=15)\n","     \n","  fig.set_size_inches(18, 10.5)\n","  fig.tight_layout()\n","  #plt.savefig('Fig_Heatmap_Model_Performance.pdf')\n","  plt.savefig('Fig_Heatmap_Model_Performance.tiff')\n","\n","make_heatmap_panel_plot()"]},{"cell_type":"code","execution_count":null,"id":"b9990be7","metadata":{"id":"b9990be7"},"outputs":[],"source":["make_heatmap('MCC_train_cv')"]},{"cell_type":"code","execution_count":null,"id":"e7febc60","metadata":{"id":"e7febc60"},"outputs":[],"source":["make_heatmap('MCC_train_test')"]},{"cell_type":"markdown","id":"8c68d02c","metadata":{"id":"8c68d02c"},"source":["### 06_Feature importance"]},{"cell_type":"code","execution_count":null,"id":"2f1dcba6","metadata":{"id":"2f1dcba6"},"outputs":[],"source":["import os\n","os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')"]},{"cell_type":"markdown","id":"9be36efb","metadata":{"id":"9be36efb"},"source":["#### Select pubchem"]},{"cell_type":"code","execution_count":null,"id":"d09ac270","metadata":{"id":"d09ac270"},"outputs":[],"source":["from zipfile import ZipFile\n","file_name = \"PARP1_oversampling_models_pkl.zip\"\n","\n","# opening the zip file in READ mode\n","with ZipFile(file_name, 'r') as zip:\n","    # printing all the contents of the zip file\n","    zip.printdir()\n","    \n","    # extracting specific file\n","    print('Extracting all the files now...')\n","    zip.extract('oversampling_PubChem_RandomForestClassifier.pkl')\n","    print('Done!')"]},{"cell_type":"code","execution_count":null,"id":"f5ac12cd","metadata":{"id":"f5ac12cd"},"outputs":[],"source":["from zipfile import ZipFile\n","file_name = \"PARP1_oversampling_lowvarianceremoved_datasplit.zip\"\n","\n","# opening the zip file in READ mode\n","with ZipFile(file_name, 'r') as zip:\n","    # printing all the contents of the zip file\n","    zip.printdir()\n","    \n","    # extracting specific file\n","    print('Extracting all the files now...')\n","    zip.extract('oversampling_PubChem_X_train.csv')\n","    zip.extract('oversampling_PubChem_y_train.csv')\n","    zip.extract('oversampling_PubChem_X_test.csv')\n","    zip.extract('oversampling_PubChem_y_test.csv')\n","    print('Done!')"]},{"cell_type":"code","execution_count":null,"id":"7e164b38","metadata":{"id":"7e164b38"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')"]},{"cell_type":"code","execution_count":null,"id":"a53c677b","metadata":{"id":"a53c677b"},"outputs":[],"source":["import pandas as pd\n","import pickle\n","\n","X_train = pd.read_csv('oversampling_PubChem_X_train.csv')\n","y_train = pd.read_csv('oversampling_PubChem_y_train.csv')\n","X_test = pd.read_csv('oversampling_PubChem_X_test.csv')\n","y_test = pd.read_csv('oversampling_PubChem_y_test.csv')\n","\n","load_model = pickle.load(open('oversampling_PubChem_RandomForestClassifier.pkl', 'rb'))\n","\n","X_train_pred = load_model.predict(X_train)"]},{"cell_type":"code","execution_count":null,"id":"cc79ba2e","metadata":{"id":"cc79ba2e"},"outputs":[],"source":["os.mkdir('gini')"]},{"cell_type":"code","execution_count":null,"id":"8a426320","metadata":{"id":"8a426320"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\gini')"]},{"cell_type":"code","execution_count":null,"id":"c0f9f917","metadata":{"id":"c0f9f917"},"outputs":[],"source":["features = pd.concat([pd.Series(X_train.columns, name='Features'), pd.Series(load_model.feature_importances_, name='Gini')], axis=1 )\n","features.sort_values(by='Gini', ascending=False, inplace=True)\n","features"]},{"cell_type":"code","execution_count":null,"id":"a235efda","metadata":{"id":"a235efda"},"outputs":[],"source":["features.to_csv('feature_Gini_oversampling_PubChem_RandomForestClassifier.csv')"]},{"cell_type":"code","execution_count":null,"id":"3b376218","metadata":{"id":"3b376218"},"outputs":[],"source":["# Create feature importance plot\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(6,8))\n","plt.barh(features.Features, features.Gini, color='#7CAE00', edgecolor='black', align='center', alpha=0.8)\n","plt.ylim(-0.5,19.5)\n","plt.gca().invert_yaxis()\n","plt.grid(True)\n","\n","plt.xlabel('Gini Index', fontsize=14, fontweight='bold', labelpad=15)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","plt.xlim(0, 0.025)\n","\n","plt.margins(0.02)\n","plt.tight_layout()\n","\n","plt.savefig('Barplot_feature_importance_oversampling_PubChem_RandomForestClassifier.tiff')"]},{"cell_type":"markdown","id":"8b48f3bc","metadata":{"id":"8b48f3bc"},"source":["### 07_PCA analysis"]},{"cell_type":"code","execution_count":null,"id":"dd28fa47","metadata":{"id":"dd28fa47"},"outputs":[],"source":["# PCA modeling\n","from sklearn.preprocessing import scale\n","from sklearn.decomposition import PCA\n","\n","# Data scaling\n","X_train = scale(X_train)\n","X_test = scale(X_test)\n","\n","# Build PCA model\n","pca = PCA()\n","pca.fit(X_train)\n","pca.fit(X_test)"]},{"cell_type":"code","execution_count":null,"id":"e45dd1e6","metadata":{"id":"e45dd1e6"},"outputs":[],"source":["os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP')\n","os.mkdir('PCA_scores')\n","os.chdir(r'C:\\Users\\tassa\\Desktop\\##Chemoinformatics\\##Code for depositing in Github\\ZIP\\PCA_scores')"]},{"cell_type":"code","execution_count":null,"id":"ac8c05af","metadata":{"scrolled":true,"id":"ac8c05af"},"outputs":[],"source":["# Screen plot\n","import matplotlib.pyplot as plt\n","import numpy as np\n","plt.plot(np.cumsum(pca.explained_variance_ratio_))\n","plt.xlabel('number of components')\n","plt.ylabel('cumulative explained variance')\n","plt.savefig('Screen plot.tiff')"]},{"cell_type":"code","execution_count":null,"id":"713b1e57","metadata":{"id":"713b1e57"},"outputs":[],"source":["# Compute PC scores train\n","scores_train = pca.transform(X_train)\n","scores_df_train = pd.DataFrame(scores_train)\n","scores_df_train"]},{"cell_type":"code","execution_count":null,"id":"f9fa6a5b","metadata":{"id":"f9fa6a5b"},"outputs":[],"source":["# Compute PC scores test\n","scores_test = pca.transform(X_test)\n","scores_df_test = pd.DataFrame(scores_test)\n","scores_df_test"]},{"cell_type":"code","execution_count":null,"id":"c78d9192","metadata":{"id":"c78d9192"},"outputs":[],"source":["scores_df_train.to_csv('scores_df_train.csv')\n","scores_df_test.to_csv('scores_df_test.csv')"]},{"cell_type":"code","execution_count":null,"id":"5ec5fd42","metadata":{"id":"5ec5fd42"},"outputs":[],"source":["#oversee max min\n","train_max = scores_df_train.values.max()\n","train_min = scores_df_train.values.min()\n","test_max = scores_df_test.values.max()\n","test_min = scores_df_test.values.min()\n","print(train_max,train_min)\n","print(test_max,test_min)"]},{"cell_type":"code","execution_count":null,"id":"b5d9a67e","metadata":{"scrolled":true,"id":"b5d9a67e"},"outputs":[],"source":["# PCA scores plot\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(25,25))\n","\n","fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n","\n","# PC1 vs PC2\n","ax1.scatter(x=scores_df_train[0], y=scores_df_train[1], c=\"#7CAE00\", alpha=0.2, edgecolor='black', label='train') #green\n","ax1.scatter(x=scores_df_test[0], y=scores_df_test[1], c=\"#f25555\", alpha=0.2, edgecolor='black', label='test') #red\n","\n","# PC1 vs PC3\n","ax2.scatter(x=scores_df_train[0], y=scores_df_train[2], c=\"#7CAE00\", alpha=0.2, edgecolor='black', label='train')\n","ax2.scatter(x=scores_df_test[0], y=scores_df_test[2], c=\"#f25555\", alpha=0.2, edgecolor='black', label='test')\n","\n","# PC2 vs PC3\n","ax3.scatter(x=scores_df_train[1], y=scores_df_train[2], c=\"#7CAE00\", alpha=0.2, edgecolor='black', label='train')\n","ax3.scatter(x=scores_df_test[1], y=scores_df_test[2], c=\"#f25555\", alpha=0.2, edgecolor='black', label='test')\n","\n","# X tick limits\n","ax1.set_xlim(-15, 20)\n","ax2.set_xlim(-15, 20)\n","ax3.set_xlim(-18, 20)\n","\n","# Y tick labels\n","ax1.set_ylim(-18, 20)\n","ax2.set_ylim(-12, 35)\n","ax3.set_ylim(-12, 35)\n","\n","# Axes labels\n","ax1.set_xlabel('PC1', fontsize=14, fontweight='bold')\n","ax1.set_ylabel('PC2', fontsize=14, fontweight='bold', labelpad = -2)\n","ax1.grid()\n","\n","ax2.set_xlabel('PC1', fontsize=14, fontweight='bold')\n","ax2.set_ylabel('PC3', fontsize=14, fontweight='bold', labelpad = -2)\n","ax2.grid()\n","\n","ax3.set_xlabel('PC2', fontsize=14, fontweight='bold')\n","ax3.set_ylabel('PC3', fontsize=14, fontweight='bold', labelpad = -2)\n","ax3.grid()\n","\n","fig.set_size_inches(15, 5)\n","\n","fig.tight_layout()\n","\n","plt.savefig('PCA_scores.tiff')"]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:chemoinf]","language":"python","name":"conda-env-chemoinf-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"2022-01-26-PARP1-TL-Deposit on Gitub.ipynb","provenance":[],"collapsed_sections":["9029d138","a81de89d","1440f5b2","1ce87473","5e9573b1","b43cbbda","9f1eba55","3feba0a8","386ea7a7","a4b31b01","206e6a9b","497e63fd","6e0acd50","e0fee62d","d2e355b6","8c68d02c","9be36efb","8b48f3bc"]}},"nbformat":4,"nbformat_minor":5}